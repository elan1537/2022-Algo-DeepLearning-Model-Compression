{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Base model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## library import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from torchsummary import summary as summary_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='./', train=True, download=False, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root='./ ', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 레이어 정의 함수"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def set_layer(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        set_weight,\n",
    "        set_bias,\n",
    "        name=''):\n",
    "\n",
    "    m = nn.Conv2d(in_channels=in_channels,\n",
    "                  out_channels=out_channels,\n",
    "                  kernel_size=kernel_size,\n",
    "                  padding='same',\n",
    "                  stride=1)\n",
    "\n",
    "    m.weight = nn.Parameter(set_weight)\n",
    "    m.bias = nn.Parameter(set_bias)\n",
    "    return m\n",
    "\n",
    "def cnn_layer_x(in_channel,\n",
    "                out_channel,\n",
    "                kernel_size,\n",
    "                weight,\n",
    "                bias):\n",
    "    return nn.Sequential(\n",
    "        collections.OrderedDict(\n",
    "            [\n",
    "                ('conv', set_layer(in_channel, out_channel, kernel_size,\n",
    "                                 set_weight   = weight,\n",
    "                                 set_bias     = bias)),\n",
    "                ('relu'    , nn.ReLU(inplace=True)),\n",
    "                ('max_pool', nn.MaxPool2d(2))\n",
    "            ]\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 베이스 모델 정의\n",
    "\n",
    "-1\n",
    "    - conv(in=1, out=4)\n",
    "    - maxpool(size=2)\n",
    "    - relu()\n",
    "\n",
    "-2\n",
    "    - conv(in=4, out=8)\n",
    "    - maxpool(size=2)\n",
    "    - relu()\n",
    "\n",
    "-3\n",
    "    - conv(in=8, out=16)\n",
    "    - maxpool(size=2)\n",
    "    - relu()\n",
    "\n",
    "-4\n",
    "    - flattern()\n",
    "    - Linear(144, 100)\n",
    "    - Relu()\n",
    "    - Linear(100, 10)\n",
    "    - softmax()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def define_model(in_channel, input_shape, out_classes):\n",
    "    div_list = lambda x: x // 2\n",
    "\n",
    "    out_channel = 4\n",
    "    kernel_size = 3\n",
    "\n",
    "    layer_1_weight = torch.normal(0, 0.01,\n",
    "                                  size=(out_channel,\n",
    "                                        in_channel,\n",
    "                                        kernel_size,\n",
    "                                        kernel_size))\n",
    "    layer_1_bias=torch.zeros(out_channel)\n",
    "\n",
    "    features_layer_one = cnn_layer_x(in_channel,\n",
    "                                     out_channel,\n",
    "                                     kernel_size,\n",
    "                                     layer_1_weight,\n",
    "                                     layer_1_bias)\n",
    "    output_shape = list(map(div_list, input_shape))\n",
    "\n",
    "    in_channel = out_channel\n",
    "    out_channel = 8\n",
    "    kernel_size = 3\n",
    "\n",
    "    layer_2_weight = torch.normal(0, 0.01,\n",
    "                                  size=(out_channel,\n",
    "                                        in_channel,\n",
    "                                        kernel_size,\n",
    "                                        kernel_size))\n",
    "    layer_2_bias=torch.zeros(out_channel)\n",
    "\n",
    "    features_layer_two = cnn_layer_x(in_channel,\n",
    "                                     out_channel,\n",
    "                                     kernel_size,\n",
    "                                     layer_2_weight,\n",
    "                                     layer_2_bias)\n",
    "\n",
    "    output_shape = list(map(div_list, output_shape))\n",
    "\n",
    "    in_channel = out_channel\n",
    "    out_channel = 16\n",
    "    kernel_size = 3\n",
    "\n",
    "    layer_3_weight = torch.normal(0, 0.01,\n",
    "                                  size=(out_channel,\n",
    "                                        in_channel,\n",
    "                                        kernel_size,\n",
    "                                        kernel_size))\n",
    "    layer_3_bias=torch.zeros(out_channel)\n",
    "\n",
    "    features_layer_three = cnn_layer_x(in_channel,\n",
    "                                       out_channel,\n",
    "                                       kernel_size,\n",
    "                                       layer_3_weight,\n",
    "                                       layer_3_bias)\n",
    "\n",
    "    output_shape = list(map(div_list, output_shape))\n",
    "\n",
    "    feature_extraction_layers_ = nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            ('layer1', features_layer_one),\n",
    "            ('layer2', features_layer_two),\n",
    "            ('layer3', features_layer_three)\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    out_channel = reduce(lambda res, element: res*element, output_shape) * out_channel\n",
    "\n",
    "    classifier = nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            ('flatten',     nn.Flatten()),\n",
    "            ('in_linear',   nn.Linear(out_channel, out_channel // 2)),\n",
    "            ('relu',        nn.ReLU(inplace=True)),\n",
    "            ('out_linear',  nn.Linear(out_channel // 2, out_classes)),\n",
    "            ('output',      nn.Softmax(dim=0)),\n",
    "        ]),\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        collections.OrderedDict(\n",
    "            [\n",
    "                ('feature_extractor', feature_extraction_layers_),\n",
    "                ('classifier', classifier)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, epochs, device='mps'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    accuracy = Accuracy(threshold=0.5).to(device)\n",
    "\n",
    "    step_accuracy = 0.0\n",
    "    step_loss = 0.0\n",
    "    step = 0\n",
    "\n",
    "    # traning loop\n",
    "    with tqdm(total=epochs * len(dataloader)) as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            for data, target in dataloader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                hyphothesis = model(data)\n",
    "                loss = criterion(hyphothesis, target)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                step_loss += loss.item()\n",
    "                step_accuracy += accuracy(hyphothesis, target)\n",
    "\n",
    "                if step % (len(dataloader) // 10) == 0:\n",
    "                    pbar.set_description(f'epoch: {epoch + 1}, step: {step + 1}, Acc: {step_accuracy / (step+1)}, loss: {step_loss / (step+1)}')\n",
    "                    step_loss = 0.0\n",
    "\n",
    "                pbar.update(1)\n",
    "                step += 1\n",
    "\n",
    "    return {\n",
    "        'acc': step_accuracy / step,\n",
    "        'loss': step_loss / step\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래 부분은 base model 학습 후 저장하는 코드임\n",
    "이미 학습을 했다면 재학습을 하지 않아도 됨"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = define_model(3, [32, 32], 100)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "summary_(model, (3, 32, 32))\n",
    "\n",
    "# train_data = datasets.MNIST(root='./mnist', train=True, download=False, transform=transforms.ToTensor())\n",
    "# test_data = datasets.MNIST(root='./mnist', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_data = datasets.CIFAR100(root='./cifar100', train=True, download=False, transform=transforms.ToTensor())\n",
    "test_data = datasets.CIFAR100(root='./cifar100', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "acc, loss = training_loop(model, train_dataloader, 50, 'cpu')\n",
    "\n",
    "# 가중치 초기화는 random value로 함 (standard)\n",
    "torch.save({\n",
    "    \"model\": model,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    'accuracy': acc,\n",
    "    \"loss\": loss}, './compressed_base_model_weight_cifar100.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR100(root='./cifar100', train=True, download=False, transform=transforms.ToTensor())\n",
    "test_data = datasets.CIFAR100(root='./cifar100', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def eval_loop(model, dataloader):\n",
    "    # evaluation 할때\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    accuracy = Accuracy(threshold=0.5, num_classes=10)\n",
    "\n",
    "    tot_acc = 0.0\n",
    "\n",
    "    for data, target in dataloader:\n",
    "        data = data.to('cpu')\n",
    "        target = target.to('cpu')\n",
    "        res = model(data)\n",
    "\n",
    "        # 0~10으로 분류함\n",
    "        probabilty, predicted = torch.max(res, 1)\n",
    "\n",
    "        # mini batch의 정확도\n",
    "        tot_acc += accuracy(predicted, target)\n",
    "\n",
    "    return tot_acc / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 학습된 모델 로딩"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = torch.load('./compressed_base_model_weight.pt')['model']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실험. 1~N개를 선택하는데 모두 시도하여 정확도를 찾음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Layer 1 (1->4)에서 feature를 선택하며 가장 정확도가 높은 조합을 찾음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "layer_idx = [0, 1, 2, 3]\n",
    "\n",
    "in_channel_one = 1\n",
    "kernel_size = 3\n",
    "device = \"cpu\"\n",
    "\n",
    "idx = 1\n",
    "time_arr = np.zeros(shape=(16,))\n",
    "acc_arr = np.zeros(shape=(16,))\n",
    "\n",
    "out_feature = 4\n",
    "\n",
    "with tqdm(total = 2 ** out_feature - 1) as pbar:\n",
    "    for selector in [1, 2, 3, 4]:\n",
    "        for comb in itertools.combinations(layer_idx, selector):\n",
    "            torch.manual_seed(888)\n",
    "            np.random.seed(888)\n",
    "            random.seed(888)\n",
    "\n",
    "            # find layer 1 best feature\n",
    "            weight = model.feature_extractor.layer1.conv.weight.to(device)[list(comb)]\n",
    "            bias   = model.feature_extractor.layer1.conv.bias.to(device)[list(comb)]\n",
    "\n",
    "            if weight.dim == 3:\n",
    "                weight = weight.unsqueeze(dim=0)\n",
    "                bias = bias.unsqueeze(dim=0)\n",
    "\n",
    "            layer_1 = cnn_layer_x(in_channel_one, selector, kernel_size, weight, bias)\n",
    "            layer_2 = cnn_layer_x(selector, 8, kernel_size,\n",
    "                                  model.feature_extractor.layer2.conv.weight.to(device)[:, list(comb)],\n",
    "                                  model.feature_extractor.layer2.conv.bias.to(device))\n",
    "            layer_3 = cnn_layer_x(8, 16, kernel_size,\n",
    "                                  model.feature_extractor.layer3.conv.weight.to(device),\n",
    "                                  model.feature_extractor.layer3.conv.bias.to(device))\n",
    "\n",
    "            modified_model = nn.Sequential(layer_1, layer_2, layer_3, model.classifier)\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            res = eval_loop(modified_model, train_dataloader)\n",
    "            end = time.perf_counter()\n",
    "\n",
    "            time_arr[idx] = end - start\n",
    "            acc_arr[idx] = res.detach()\n",
    "            idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f'layer: {bin(idx)}, time: {end - start}, acc: {res.detach()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_arr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc_arr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Layer 2 (4->8)에서 feature를 선택하며 가장 정확도가 높은 조합을 찾음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "layer_idx = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "in_channel_one = 1\n",
    "kernel_size = 3\n",
    "device = \"cpu\"\n",
    "\n",
    "idx = 1\n",
    "out_feature = 8\n",
    "\n",
    "time_arr = np.zeros(shape=(2**8,))\n",
    "acc_arr = np.zeros(shape=(2**8,))\n",
    "\n",
    "with tqdm(total = 2 ** out_feature - 1) as pbar:\n",
    "    for selector in list(map(lambda x: x+1, layer_idx)):\n",
    "        for comb in itertools.combinations(layer_idx, selector):\n",
    "            torch.manual_seed(888)\n",
    "            np.random.seed(888)\n",
    "            random.seed(888)\n",
    "\n",
    "            # find layer 2 best feature\n",
    "            weight = model.feature_extractor.layer2.conv.weight.to(device)[list(comb)]\n",
    "            bias   = model.feature_extractor.layer2.conv.bias.to(device)[list(comb)]\n",
    "\n",
    "            layer_1 = cnn_layer_x(1, 4, kernel_size,\n",
    "                                  model.feature_extractor.layer1.conv.weight.to(device),\n",
    "                                  model.feature_extractor.layer1.conv.bias.to(device))\n",
    "            layer_2 = cnn_layer_x(4, selector, kernel_size,\n",
    "                                  weight,\n",
    "                                  bias)\n",
    "            layer_3 = cnn_layer_x(selector, 16, kernel_size,\n",
    "                                  model.feature_extractor.layer3.conv.weight.to(device)[:, list(comb)],\n",
    "                                  model.feature_extractor.layer3.conv.bias.to(device))\n",
    "\n",
    "            modified_model = nn.Sequential(layer_1, layer_2, layer_3, model.classifier)\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            res = eval_loop(modified_model, train_dataloader)\n",
    "            end = time.perf_counter()\n",
    "\n",
    "            time_arr[idx] = end - start\n",
    "            acc_arr[idx] = res.detach()\n",
    "            idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f'layer: {bin(idx)}, time: {end - start}, acc: {res.detach()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Layer 3 (8->16)에서 feature를 선택하며 가장 정확도가 높은 조합을 찾음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "layer_idx = list(range(16))\n",
    "\n",
    "in_channel_one = 1\n",
    "kernel_size = 3\n",
    "device = \"cpu\"\n",
    "\n",
    "idx = 256\n",
    "out_feature = len(layer_idx)\n",
    "\n",
    "time_arr = np.zeros(shape=(2**out_feature,))\n",
    "acc_arr = np.zeros(shape=(2**out_feature,))\n",
    "\n",
    "with tqdm(total = 2 ** out_feature - len(bin(idx))-2 - 1) as pbar:\n",
    "    for selector in list(map(lambda x: x+1, layer_idx)):\n",
    "        for comb in list(itertools.combinations(layer_idx, selector))[idx:]:\n",
    "            torch.manual_seed(888)\n",
    "            np.random.seed(888)\n",
    "            random.seed(888)\n",
    "\n",
    "            # find layer 2 best feature\n",
    "            weight = model.feature_extractor.layer3.conv.weight.to(device)[list(comb)]\n",
    "            bias   = model.feature_extractor.layer3.conv.bias.to(device)[list(comb)]\n",
    "\n",
    "            layer_1 = cnn_layer_x(1, 4, kernel_size,\n",
    "                                  model.feature_extractor.layer1.conv.weight.to(device),\n",
    "                                  model.feature_extractor.layer1.conv.bias.to(device))\n",
    "            layer_2 = cnn_layer_x(4, 8, kernel_size,\n",
    "                                  model.feature_extractor.layer2.conv.weight.to(device),\n",
    "                                  model.feature_extractor.layer2.conv.bias.to(device))\n",
    "            layer_3 = cnn_layer_x(8, selector, kernel_size,\n",
    "                                  weight,\n",
    "                                  bias)\n",
    "\n",
    "            res_flatten_idx = list(reduce(lambda res, e: res + e, map(lambda x: [i + (3*3)*x for i in range(3*3)], comb)))\n",
    "\n",
    "            linear_weight = model.classifier.in_linear.weight[:, res_flatten_idx]\n",
    "            linear_bias = model.classifier.in_linear.bias\n",
    "\n",
    "            classifier = nn.Sequential(\n",
    "                collections.OrderedDict([\n",
    "                    ('flatten', nn.Flatten()),\n",
    "                    ('in_linear', nn.Linear(selector * 3 * 3, 100)),\n",
    "                    ('relu', nn.ReLU(inplace=True)),\n",
    "                    ('out_linear', nn.Linear(100, 10)),\n",
    "                    ('output', nn.Softmax(dim=0))\n",
    "                ])\n",
    "            )\n",
    "\n",
    "            classifier.in_linear.weight = nn.Parameter(linear_weight)\n",
    "            classifier.in_linear.bias = nn.Parameter(linear_bias)\n",
    "\n",
    "            modified_model = nn.Sequential(layer_1, layer_2, layer_3, classifier)\n",
    "\n",
    "            # 144 -> 16 * 3 * 3\n",
    "            # 72  -> 8 * 3 * 3\n",
    "\n",
    "            start = time.perf_counter()\n",
    "            res = eval_loop(modified_model, train_dataloader)\n",
    "            end = time.perf_counter()\n",
    "\n",
    "            time_arr[idx] = end - start\n",
    "            acc_arr[idx] = res.detach()\n",
    "            idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f'layer: {bin(idx).replace(\"0b\", \"\").zfill(out_feature)}, time: {end - start}, acc: {res.detach()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실험. 2 1 ~ N개를 선택하는데 빠르게 찾기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "'''\n",
    "    find_layer_n_best_feature(model_weights, model_feature_selection) -> best_feature_combinations\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (feature_extractor): Sequential(\n    (layer1): Sequential(\n      (conv): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU(inplace=True)\n      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (layer2): Sequential(\n      (conv): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU(inplace=True)\n      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (layer3): Sequential(\n      (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n      (relu): ReLU(inplace=True)\n      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n  )\n  (classifier): Sequential(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n    (in_linear): Linear(in_features=144, out_features=100, bias=True)\n    (relu): ReLU(inplace=True)\n    (out_linear): Linear(in_features=100, out_features=10, bias=True)\n    (output): Softmax(dim=0)\n  )\n)"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9817)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_loop(model, train_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def layer_1_define(comb):\n",
    "        torch.manual_seed(888)\n",
    "        np.random.seed(888)\n",
    "        random.seed(888)\n",
    "\n",
    "        # find layer 1 best feature\n",
    "        weight = model.feature_extractor.layer1.conv.weight.to(device)[list(comb)]\n",
    "        bias   = model.feature_extractor.layer1.conv.bias.to(device)[list(comb)]\n",
    "\n",
    "        if weight.dim == 3:\n",
    "            weight = weight.unsqueeze(dim=0)\n",
    "            bias = bias.unsqueeze(dim=0)\n",
    "\n",
    "        layer_1 = cnn_layer_x(in_channel_one, len(comb), kernel_size, weight, bias)\n",
    "        layer_2 = cnn_layer_x(len(comb), 8, kernel_size,\n",
    "                              model.feature_extractor.layer2.conv.weight.to(device)[:, list(comb)],\n",
    "                              model.feature_extractor.layer2.conv.bias.to(device))\n",
    "        layer_3 = cnn_layer_x(8, 16, kernel_size,\n",
    "                              model.feature_extractor.layer3.conv.weight.to(device),\n",
    "                              model.feature_extractor.layer3.conv.bias.to(device))\n",
    "\n",
    "        params_size = 1 * len(comb) * 3 * 3 + len(comb) + 4*8*3*3+4+8*16*3*3+8 + 144*100+100 + 100*10+10\n",
    "\n",
    "        modified_model = nn.Sequential(layer_1, layer_2, layer_3, model.classifier)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        res = eval_loop(modified_model, train_dataloader)\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        return end - start, res.detach().cpu().numpy().tolist(), params_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "in_channel_one = 1\n",
    "kernel_size = 3\n",
    "device = \"cpu\"\n",
    "\n",
    "def layer_2_define(comb):\n",
    "    torch.manual_seed(888)\n",
    "    np.random.seed(888)\n",
    "    random.seed(888)\n",
    "\n",
    "        # find layer 2 best feature\n",
    "    selector = len(comb)\n",
    "\n",
    "    layer_1 = cnn_layer_x(1, 4, kernel_size,\n",
    "                          model.feature_extractor.layer1.conv.weight.to(device),\n",
    "                          model.feature_extractor.layer1.conv.bias.to(device))\n",
    "    layer_2 = cnn_layer_x(4, selector, kernel_size,\n",
    "                          model.feature_extractor.layer2.conv.weight.to(device)[list(comb)],\n",
    "                          model.feature_extractor.layer2.conv.bias.to(device)[list(comb)])\n",
    "    layer_3 = cnn_layer_x(selector, 16, kernel_size,\n",
    "                          model.feature_extractor.layer3.conv.weight.to(device)[:, list(comb)],\n",
    "                          model.feature_extractor.layer3.conv.bias.to(device))\n",
    "\n",
    "\n",
    "    params_size = 1*4*3*3+4 + 4*selector*3*3+8 + selector*16*3*3+8 + 16*3*3*100+100 + 100*10+10\n",
    "\n",
    "    modified_model = nn.Sequential(layer_1, layer_2, layer_3, model.classifier)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    res = eval_loop(modified_model, train_dataloader)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    return end - start, res.detach().cpu().numpy().tolist(), params_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def layer_3_define(comb):\n",
    "    torch.manual_seed(888)\n",
    "    np.random.seed(888)\n",
    "    random.seed(888)\n",
    "\n",
    "    selector = len(comb)\n",
    "    layer_1 = cnn_layer_x(1, 4, kernel_size,\n",
    "                          model.feature_extractor.layer1.conv.weight.to(device),\n",
    "                          model.feature_extractor.layer1.conv.bias.to(device))\n",
    "    layer_2 = cnn_layer_x(4, 8, kernel_size,\n",
    "                          model.feature_extractor.layer2.conv.weight.to(device),\n",
    "                          model.feature_extractor.layer2.conv.bias.to(device))\n",
    "\n",
    "    weight = model.feature_extractor.layer3.conv.weight.to(device)[comb]\n",
    "    bias   = model.feature_extractor.layer3.conv.bias.to(device)[comb]\n",
    "    layer_3 = cnn_layer_x(8, selector, kernel_size,\n",
    "                          weight,\n",
    "                          bias)\n",
    "\n",
    "    res_flatten_idx = list(reduce(lambda res, e: res + e,\n",
    "                                  map(lambda x: [i + (3 * 3) * x for i in range(3 * 3)], comb)))\n",
    "\n",
    "    params_size = 1*4*3*3+4 + 4*8*3*3+8 + 8*selector*3*3+selector + len(res_flatten_idx)*100+100 + 100*10+10\n",
    "\n",
    "    linear_weight = model.classifier.in_linear.weight[:, res_flatten_idx]\n",
    "    linear_bias = model.classifier.in_linear.bias\n",
    "\n",
    "    classifier = nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('in_linear', nn.Linear(selector * 3 * 3, 100)),\n",
    "            ('relu', nn.ReLU(inplace=True)),\n",
    "            ('out_linear', nn.Linear(100, 10)),\n",
    "            ('output', nn.Softmax(dim=0))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    classifier.in_linear.weight = nn.Parameter(linear_weight)\n",
    "    classifier.in_linear.bias = nn.Parameter(linear_bias)\n",
    "    classifier.out_linear.weight = nn.Parameter(model.classifier.out_linear.weight)\n",
    "    classifier.out_linear.bias = nn.Parameter(model.classifier.out_linear.bias)\n",
    "\n",
    "    modified_model = nn.Sequential(layer_1, layer_2, layer_3, classifier)\n",
    "    start = time.perf_counter()\n",
    "    res = eval_loop(modified_model, train_dataloader)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    return end - start, res.detach().cpu().numpy().tolist(), params_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def layer_3_define_ordered(comb):\n",
    "    torch.manual_seed(888)\n",
    "    np.random.seed(888)\n",
    "    random.seed(888)\n",
    "\n",
    "    selector = len(comb)\n",
    "    layer_1 = cnn_layer_x(1, 4, kernel_size,\n",
    "                          model.feature_extractor.layer1.conv.weight.to(device),\n",
    "                          model.feature_extractor.layer1.conv.bias.to(device))\n",
    "    layer_2 = cnn_layer_x(4, 8, kernel_size,\n",
    "                          model.feature_extractor.layer2.conv.weight.to(device),\n",
    "                          model.feature_extractor.layer2.conv.bias.to(device))\n",
    "\n",
    "    weight = torch.tensor([])\n",
    "    bias = torch.tensor([])\n",
    "    for c in comb:\n",
    "        weight = torch.concat([weight, model.feature_extractor.layer3.conv.weight.to(device)[c][np.newaxis]], dim=0)\n",
    "        bias  = torch.concat([bias, model.feature_extractor.layer3.conv.bias.to(device)[c][np.newaxis]], dim=0)\n",
    "\n",
    "    layer_3 = cnn_layer_x(8, selector, kernel_size,\n",
    "                          weight,\n",
    "                          bias)\n",
    "\n",
    "    res_flatten_idx = list(reduce(lambda res, e: res + e,\n",
    "                                  map(lambda x: [i + (3 * 3) * x for i in range(3 * 3)], comb)))\n",
    "\n",
    "    linear_weight = torch.tensor([])\n",
    "    linear_bias = model.classifier.in_linear.bias\n",
    "\n",
    "    for res_flat in map(lambda x: [i + (3 * 3) * x for i in range(3 * 3)], comb):\n",
    "        linear_weight = torch.concat([linear_weight, model.classifier.in_linear.weight[:, res_flat]], dim=1)\n",
    "\n",
    "    print(linear_weight.shape)\n",
    "\n",
    "    params_size = 1*4*3*3+4 + 4*8*3*3+8 + 8*selector*3*3+selector + len(res_flatten_idx)*100+100 + 100*10+10\n",
    "\n",
    "    classifier = nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('in_linear', nn.Linear(selector * 3 * 3, 100)),\n",
    "            ('relu', nn.ReLU(inplace=True)),\n",
    "            ('out_linear', nn.Linear(100, 10)),\n",
    "            ('output', nn.Softmax(dim=0))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    classifier.in_linear.weight = nn.Parameter(linear_weight)\n",
    "    classifier.in_linear.bias = nn.Parameter(linear_bias)\n",
    "    classifier.out_linear.weight = nn.Parameter(model.classifier.out_linear.weight)\n",
    "    classifier.out_linear.bias = nn.Parameter(model.classifier.out_linear.bias)\n",
    "\n",
    "    modified_model = nn.Sequential(layer_1, layer_2, layer_3, classifier)\n",
    "    start = time.perf_counter()\n",
    "    res = eval_loop(modified_model, train_dataloader)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    return end - start, res.detach().cpu().numpy().tolist(), params_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 전체 피쳐를 선택했을 때 결과 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "comb = np.arange(0, 16)\n",
    "\n",
    "import pandas as pd\n",
    "table = pd.DataFrame([], columns=['combination', 'time', 'accuracy', 'param_size', 'feature_selected'])\n",
    "\n",
    "calc_time, accuracy, param_size = layer_3_define(comb)\n",
    "\n",
    "result = {'combination': [str(comb)],\n",
    "          'time': [calc_time],\n",
    "          'accuracy': [accuracy],\n",
    "          'param_size': [param_size],\n",
    "          'feature_selected': [len(comb)]}\n",
    "\n",
    "table = pd.concat([table, pd.DataFrame.from_dict(result)], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## feature를 N/2개 선택했을 때"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.769374957999844 0.96706754 24798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0, 3, 4, 7, 8, 11, 12, 15] 3.0791446660000474 0.9227911829948425 9230: 100%|██████████| 81/81 [04:18<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "def select(base):\n",
    "    comb = []\n",
    "    for i in range(1, 4):\n",
    "        comb += [[base] + [i + base]]\n",
    "\n",
    "    return comb\n",
    "\n",
    "res = []\n",
    "for i in range(0, 16, 4):\n",
    "    res += [select(i)]\n",
    "\n",
    "\n",
    "r = []\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        r += res[i][j]\n",
    "\n",
    "idx = 0\n",
    "with tqdm(total=81) as pbar:\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    comb = res[0][i] + res[1][j] + res[2][k] + res[3][l]\n",
    "                    calc_time, acc, param_size = layer_3_define(comb)\n",
    "\n",
    "                    result = [{'combination': str(np.array(comb)),\n",
    "                              'time': calc_time,\n",
    "                              'accuracy': acc,\n",
    "                              'param_size': param_size,\n",
    "                              'feature_selected': len(comb)}]\n",
    "\n",
    "                    table = pd.concat([table, pd.DataFrame.from_dict(result)], ignore_index=True)\n",
    "\n",
    "                    pbar.set_description(\"{0} {1:5} {2} {3}\".format(comb, calc_time, acc, param_size))\n",
    "                    pbar.update(1)\n",
    "                    idx += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "                  combination      time    accuracy param_size  \\\n67  [ 0  3  4  6  8 10 12 14]  3.277873   0.9425473       9230   \n64  [ 0  3  4  6  8  9 12 14]  3.080173   0.9346515       9230   \n4   [ 0  1  4  5  8 10 12 14]  3.500545   0.9315365       9230   \n58  [ 0  3  4  5  8 10 12 14]  3.073434   0.9246902       9230   \n80  [ 0  3  4  7  8 11 12 15]  3.079145   0.9227912       9230   \n..                        ...       ...         ...        ...   \n47  [ 0  2  4  7  8  9 12 15]  3.081601  0.73340887       9230   \n46  [ 0  2  4  7  8  9 12 14]  3.090284  0.71135396       9230   \n51  [ 0  2  4  7  8 11 12 13]  3.077183  0.69509596       9230   \n48  [ 0  2  4  7  8 10 12 13]  3.090919  0.68316895       9230   \n45  [ 0  2  4  7  8  9 12 13]  3.087479  0.65973145       9230   \n\n   feature_selected  \n67                8  \n64                8  \n4                 8  \n58                8  \n80                8  \n..              ...  \n47                8  \n46                8  \n51                8  \n48                8  \n45                8  \n\n[81 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>67</th>\n      <td>[ 0  3  4  6  8 10 12 14]</td>\n      <td>3.277873</td>\n      <td>0.9425473</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>[ 0  3  4  6  8  9 12 14]</td>\n      <td>3.080173</td>\n      <td>0.9346515</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[ 0  1  4  5  8 10 12 14]</td>\n      <td>3.500545</td>\n      <td>0.9315365</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>[ 0  3  4  5  8 10 12 14]</td>\n      <td>3.073434</td>\n      <td>0.9246902</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>[ 0  3  4  7  8 11 12 15]</td>\n      <td>3.079145</td>\n      <td>0.9227912</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>[ 0  2  4  7  8  9 12 15]</td>\n      <td>3.081601</td>\n      <td>0.73340887</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>[ 0  2  4  7  8  9 12 14]</td>\n      <td>3.090284</td>\n      <td>0.71135396</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>[ 0  2  4  7  8 11 12 13]</td>\n      <td>3.077183</td>\n      <td>0.69509596</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>[ 0  2  4  7  8 10 12 13]</td>\n      <td>3.090919</td>\n      <td>0.68316895</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>[ 0  2  4  7  8  9 12 13]</td>\n      <td>3.087479</td>\n      <td>0.65973145</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>81 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values('accuracy', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "outputs": [],
   "source": [
    "table.to_csv('./layer3_select_8_res.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "table = pd.read_csv('./layer3_select_res.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## N-1개를 선택하여 최적 피쳐 찾기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def append_metric_to_table(selections, calc_time, accuracy, param_size, table):\n",
    "    result = {'combination': [str(selections)],\n",
    "              'time': [calc_time],\n",
    "              'accuracy': [accuracy],\n",
    "              'param_size': [param_size],\n",
    "              'feature_selected': [len(selections)]}\n",
    "\n",
    "    return pd.concat([table, pd.DataFrame.from_dict(result)], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] 3.6366744160000053 0.9227911829948425 16041: : 16it [00:53,  3.32s/it]                      \n"
     ]
    }
   ],
   "source": [
    "comb = np.arange(0, 16)\n",
    "\n",
    "idx = 0\n",
    "with tqdm(total=len(comb) - 1) as pbar:\n",
    "    while idx != len(comb):\n",
    "        split_one, _, split_two = np.array_split(comb, [idx, idx+1], axis=0)\n",
    "        selections = np.concatenate([split_one, split_two])\n",
    "\n",
    "        calc_time, accuracy, param_size = layer_3_define(selections)\n",
    "\n",
    "        result = {'combination': [str(selections)],\n",
    "                  'time': [calc_time],\n",
    "                  'accuracy': [accuracy],\n",
    "                  'param_size': [param_size],\n",
    "                  'feature_selected': [len(selections)]}\n",
    "\n",
    "        table = pd.concat([table, pd.DataFrame.from_dict(result)], ignore_index=True)\n",
    "\n",
    "        pbar.set_description(\"{0} {1:5} {2} {3}\".format(selections, calc_time, accuracy, param_size))\n",
    "        pbar.update(1)\n",
    "        idx += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0                                        combination      time  \\\n0            0                          [ 0  1  4  5  8  9 12 13]  3.129518   \n1            1                          [ 0  1  4  5  8  9 12 14]  3.125745   \n2            2                          [ 0  1  4  5  8  9 12 15]  3.109206   \n3            3                          [ 0  1  4  5  8 10 12 13]  3.441142   \n4            4                          [ 0  1  4  5  8 10 12 14]  3.500545   \n..         ...                                                ...       ...   \n93          93     [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15]  3.182057   \n94          94     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]  3.206404   \n95          95     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15]  3.882307   \n96          96     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]  3.636674   \n97          97  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]  4.345235   \n\n    accuracy  param_size  feature_selected  \n0   0.858809        9230                 8  \n1   0.903135        9230                 8  \n2   0.851612        9230                 8  \n3   0.900536        9230                 8  \n4   0.931536        9230                 8  \n..       ...         ...               ...  \n93  0.976079       16041                15  \n94  0.980777       16041                15  \n95  0.977262       16041                15  \n96  0.979394       16041                15  \n97  0.982076       17014                16  \n\n[98 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[ 0  1  4  5  8  9 12 13]</td>\n      <td>3.129518</td>\n      <td>0.858809</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[ 0  1  4  5  8  9 12 14]</td>\n      <td>3.125745</td>\n      <td>0.903135</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[ 0  1  4  5  8  9 12 15]</td>\n      <td>3.109206</td>\n      <td>0.851612</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[ 0  1  4  5  8 10 12 13]</td>\n      <td>3.441142</td>\n      <td>0.900536</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[ 0  1  4  5  8 10 12 14]</td>\n      <td>3.500545</td>\n      <td>0.931536</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>93</td>\n      <td>[ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15]</td>\n      <td>3.182057</td>\n      <td>0.976079</td>\n      <td>16041</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>94</td>\n      <td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15]</td>\n      <td>3.206404</td>\n      <td>0.980777</td>\n      <td>16041</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>95</td>\n      <td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15]</td>\n      <td>3.882307</td>\n      <td>0.977262</td>\n      <td>16041</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>96</td>\n      <td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]</td>\n      <td>3.636674</td>\n      <td>0.979394</td>\n      <td>16041</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>97</td>\n      <td>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]</td>\n      <td>4.345235</td>\n      <td>0.982076</td>\n      <td>17014</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n<p>98 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### N-1을 선택했을때 가장 정확도가 높은 피쳐 선택\n",
    "\n",
    "개별 피쳐를 넣어서 결과를 도출했을 때 각 피쳐의 정확도를 도출함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "max_15_selection = table[table['feature_selected'] == 15].max().combination"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "max_15_selection = np.fromstring(max_15_selection.lstrip('[').rstrip(']'), sep=' ', dtype=np.int32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 3.6642519580000226 0.2805004 2419\n",
      "[2] 3.2096052920001057 0.24985008 2419\n",
      "[3] 3.0922785829999384 0.42324093 2419\n",
      "[4] 3.124734958999966 0.38339552 2419\n",
      "[5] 3.108341792000033 0.35662645 2419\n",
      "[6] 3.1135462920000236 0.37388393 2419\n",
      "[7] 3.1174400830000195 0.48069364 2419\n",
      "[8] 3.1145645000000286 0.4842251 2419\n",
      "[9] 3.1145911669999577 0.098697364 2419\n",
      "[10] 3.151665624999964 0.50194895 2419\n",
      "[11] 3.178392457999962 0.22891125 2419\n",
      "[12] 3.1300031660000514 0.36650452 2419\n",
      "[13] 3.1742277920000106 0.42312434 2419\n",
      "[14] 3.1248830420000786 0.40864873 2419\n",
      "[15] 3.143935082999974 0.35434434 2419\n"
     ]
    }
   ],
   "source": [
    "for elem in max_15_selection:\n",
    "    calc_time, acc, param_size = layer_3_define([elem])\n",
    "    print([elem], calc_time, acc, param_size)\n",
    "    table = append_metric_to_table(np.array([elem]), calc_time, acc, param_size, table)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "다음과 같이 개별 feature의 정확도를 정렬함\n",
    "현재 결과에서 [10] feature가 정확도가 높은 것 (0.5)로 확인함\n",
    "[9] feature는 정확도가 0.098로 추론 결과에 영향력이 미비한 것을 예상해볼 수 있음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "    combination      time     accuracy  param_size  feature_selected\n107        [10]  3.151666   0.50194895        2419                 1\n105         [8]  3.114565    0.4842251        2419                 1\n104         [7]  3.117440   0.48069364        2419                 1\n100         [3]  3.092279   0.42324093        2419                 1\n110        [13]  3.174228   0.42312434        2419                 1\n111        [14]  3.124883   0.40864873        2419                 1\n101         [4]  3.124735   0.38339552        2419                 1\n103         [6]  3.113546   0.37388393        2419                 1\n109        [12]  3.130003   0.36650452        2419                 1\n102         [5]  3.108342   0.35662645        2419                 1\n112        [15]  3.143935   0.35434434        2419                 1\n98          [1]  3.664252    0.2805004        2419                 1\n99          [2]  3.209605   0.24985008        2419                 1\n108        [11]  3.178392   0.22891125        2419                 1\n106         [9]  3.114591  0.098697364        2419                 1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>107</th>\n      <td>[10]</td>\n      <td>3.151666</td>\n      <td>0.50194895</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>[8]</td>\n      <td>3.114565</td>\n      <td>0.4842251</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>[7]</td>\n      <td>3.117440</td>\n      <td>0.48069364</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>[3]</td>\n      <td>3.092279</td>\n      <td>0.42324093</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>110</th>\n      <td>[13]</td>\n      <td>3.174228</td>\n      <td>0.42312434</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>[14]</td>\n      <td>3.124883</td>\n      <td>0.40864873</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>[4]</td>\n      <td>3.124735</td>\n      <td>0.38339552</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>[6]</td>\n      <td>3.113546</td>\n      <td>0.37388393</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>[12]</td>\n      <td>3.130003</td>\n      <td>0.36650452</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>[5]</td>\n      <td>3.108342</td>\n      <td>0.35662645</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>[15]</td>\n      <td>3.143935</td>\n      <td>0.35434434</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>[1]</td>\n      <td>3.664252</td>\n      <td>0.2805004</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>[2]</td>\n      <td>3.209605</td>\n      <td>0.24985008</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>[11]</td>\n      <td>3.178392</td>\n      <td>0.22891125</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>[9]</td>\n      <td>3.114591</td>\n      <td>0.098697364</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[table['feature_selected'] == 1].sort_values(by='accuracy', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "features_sorted = table[table['feature_selected'] == 1].sort_values(by='accuracy', ascending=False).combination.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "['[10]',\n '[8]',\n '[7]',\n '[3]',\n '[13]',\n '[14]',\n '[4]',\n '[6]',\n '[12]',\n '[5]',\n '[15]',\n '[1]',\n '[2]',\n '[11]',\n '[9]']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sorted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "string 형식으로 결과가 반환됬기 때문에 배열, 숫자 타입으로 변환한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5, 15, 1, 2, 11, 9]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sorted = list(map(lambda x: int(x.lstrip('[').rstrip(']')), features_sorted))\n",
    "features_sorted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "정확도가 높은 순으로 정렬된 feature를 i개를 추가하여 추론결과를 도출할 때 정확도와 상관관계가 어떻게 되는지 살펴본다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\n",
      "3.9154185829997914 0.50194895 2419\n",
      "[10, 8]\n",
      "3.1468911669999216 0.5692297 3392\n",
      "[10, 8, 7]\n",
      "3.156260249999832 0.6394423 4365\n",
      "[10, 8, 7, 3]\n",
      "3.164357999999993 0.7413879 5338\n",
      "[10, 8, 7, 3, 13]\n",
      "3.1793600419996437 0.7602112 6311\n",
      "[10, 8, 7, 3, 13, 14]\n",
      "3.177221083999939 0.8053038 7284\n",
      "[10, 8, 7, 3, 13, 14, 4]\n",
      "3.3246117909998247 0.79449296 8257\n",
      "[10, 8, 7, 3, 13, 14, 4, 6]\n",
      "3.198178165999707 0.8897255 9230\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12]\n",
      "3.2253964169999563 0.94224745 10203\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5]\n",
      "3.316228540999873 0.9477945 11176\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5, 15]\n",
      "3.2695937080002295 0.9539246 12149\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5, 15, 1]\n",
      "3.3519042079997234 0.96037114 13122\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5, 15, 1, 2]\n",
      "4.396823874999882 0.974397 14095\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5, 15, 1, 2, 11]\n",
      "4.056553249999979 0.98134327 15068\n",
      "[10, 8, 7, 3, 13, 14, 4, 6, 12, 5, 15, 1, 2, 11, 9]\n",
      "3.805976125000143 0.98117673 16041\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "\n",
    "table_for_one = pd.DataFrame([], columns=['combination', 'time', 'accuracy', 'param_size', 'feature_selected'])\n",
    "\n",
    "while idx != len(features_sorted) + 1:\n",
    "    print(features_sorted[:idx])\n",
    "    calc_time, acc, param_size = layer_3_define(features_sorted[:idx])\n",
    "    table_for_one = append_metric_to_table(np.array(features_sorted[:idx]), calc_time, acc, param_size, table_for_one)\n",
    "    print(calc_time, acc, param_size)\n",
    "    idx += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       combination      time    accuracy  \\\n0                                             [10]  3.915419  0.50194895   \n1                                          [10  8]  3.146891   0.5692297   \n2                                       [10  8  7]  3.156260   0.6394423   \n3                                    [10  8  7  3]  3.164358   0.7413879   \n4                                 [10  8  7  3 13]  3.179360   0.7602112   \n5                              [10  8  7  3 13 14]  3.177221   0.8053038   \n6                           [10  8  7  3 13 14  4]  3.324612  0.79449296   \n7                        [10  8  7  3 13 14  4  6]  3.198178   0.8897255   \n8                     [10  8  7  3 13 14  4  6 12]  3.225396  0.94224745   \n9                  [10  8  7  3 13 14  4  6 12  5]  3.316229   0.9477945   \n10              [10  8  7  3 13 14  4  6 12  5 15]  3.269594   0.9539246   \n11           [10  8  7  3 13 14  4  6 12  5 15  1]  3.351904  0.96037114   \n12        [10  8  7  3 13 14  4  6 12  5 15  1  2]  4.396824    0.974397   \n13     [10  8  7  3 13 14  4  6 12  5 15  1  2 11]  4.056553  0.98134327   \n14  [10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]  3.805976  0.98117673   \n\n   param_size feature_selected  \n0        2419                1  \n1        3392                2  \n2        4365                3  \n3        5338                4  \n4        6311                5  \n5        7284                6  \n6        8257                7  \n7        9230                8  \n8       10203                9  \n9       11176               10  \n10      12149               11  \n11      13122               12  \n12      14095               13  \n13      15068               14  \n14      16041               15  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[10]</td>\n      <td>3.915419</td>\n      <td>0.50194895</td>\n      <td>2419</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[10  8]</td>\n      <td>3.146891</td>\n      <td>0.5692297</td>\n      <td>3392</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[10  8  7]</td>\n      <td>3.156260</td>\n      <td>0.6394423</td>\n      <td>4365</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[10  8  7  3]</td>\n      <td>3.164358</td>\n      <td>0.7413879</td>\n      <td>5338</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[10  8  7  3 13]</td>\n      <td>3.179360</td>\n      <td>0.7602112</td>\n      <td>6311</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[10  8  7  3 13 14]</td>\n      <td>3.177221</td>\n      <td>0.8053038</td>\n      <td>7284</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[10  8  7  3 13 14  4]</td>\n      <td>3.324612</td>\n      <td>0.79449296</td>\n      <td>8257</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[10  8  7  3 13 14  4  6]</td>\n      <td>3.198178</td>\n      <td>0.8897255</td>\n      <td>9230</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[10  8  7  3 13 14  4  6 12]</td>\n      <td>3.225396</td>\n      <td>0.94224745</td>\n      <td>10203</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[10  8  7  3 13 14  4  6 12  5]</td>\n      <td>3.316229</td>\n      <td>0.9477945</td>\n      <td>11176</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15]</td>\n      <td>3.269594</td>\n      <td>0.9539246</td>\n      <td>12149</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1]</td>\n      <td>3.351904</td>\n      <td>0.96037114</td>\n      <td>13122</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2]</td>\n      <td>4.396824</td>\n      <td>0.974397</td>\n      <td>14095</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11]</td>\n      <td>4.056553</td>\n      <td>0.98134327</td>\n      <td>15068</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]</td>\n      <td>3.805976</td>\n      <td>0.98117673</td>\n      <td>16041</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "각 피쳐간 변화율을 살펴보자"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "idx = 0\n",
    "while idx != len(features_sorted) - 1:\n",
    "    delta = table_for_one.loc[idx+1, 'accuracy'] - table_for_one.loc[idx, 'accuracy']\n",
    "\n",
    "    table_for_one.loc[idx+1, 'delta'] = delta\n",
    "    idx += 1\n",
    "\n",
    "table_for_one.loc[0, 'delta'] = 0.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       combination      time    accuracy  \\\n0                                             [10]  3.915419  0.50194895   \n1                                          [10  8]  3.146891   0.5692297   \n2                                       [10  8  7]  3.156260   0.6394423   \n3                                    [10  8  7  3]  3.164358   0.7413879   \n4                                 [10  8  7  3 13]  3.179360   0.7602112   \n5                              [10  8  7  3 13 14]  3.177221   0.8053038   \n6                           [10  8  7  3 13 14  4]  3.324612  0.79449296   \n7                        [10  8  7  3 13 14  4  6]  3.198178   0.8897255   \n8                     [10  8  7  3 13 14  4  6 12]  3.225396  0.94224745   \n9                  [10  8  7  3 13 14  4  6 12  5]  3.316229   0.9477945   \n10              [10  8  7  3 13 14  4  6 12  5 15]  3.269594   0.9539246   \n11           [10  8  7  3 13 14  4  6 12  5 15  1]  3.351904  0.96037114   \n12        [10  8  7  3 13 14  4  6 12  5 15  1  2]  4.396824    0.974397   \n13     [10  8  7  3 13 14  4  6 12  5 15  1  2 11]  4.056553  0.98134327   \n14  [10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]  3.805976  0.98117673   \n\n   param_size feature_selected     delta  \n0        2419                1  0.000000  \n1        3392                2  0.067281  \n2        4365                3  0.070213  \n3        5338                4  0.101946  \n4        6311                5  0.018823  \n5        7284                6  0.045093  \n6        8257                7 -0.010811  \n7        9230                8  0.095233  \n8       10203                9  0.052522  \n9       11176               10  0.005547  \n10      12149               11  0.006130  \n11      13122               12  0.006447  \n12      14095               13  0.014026  \n13      15068               14  0.006946  \n14      16041               15 -0.000167  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n      <th>delta</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[10]</td>\n      <td>3.915419</td>\n      <td>0.50194895</td>\n      <td>2419</td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[10  8]</td>\n      <td>3.146891</td>\n      <td>0.5692297</td>\n      <td>3392</td>\n      <td>2</td>\n      <td>0.067281</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[10  8  7]</td>\n      <td>3.156260</td>\n      <td>0.6394423</td>\n      <td>4365</td>\n      <td>3</td>\n      <td>0.070213</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[10  8  7  3]</td>\n      <td>3.164358</td>\n      <td>0.7413879</td>\n      <td>5338</td>\n      <td>4</td>\n      <td>0.101946</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[10  8  7  3 13]</td>\n      <td>3.179360</td>\n      <td>0.7602112</td>\n      <td>6311</td>\n      <td>5</td>\n      <td>0.018823</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[10  8  7  3 13 14]</td>\n      <td>3.177221</td>\n      <td>0.8053038</td>\n      <td>7284</td>\n      <td>6</td>\n      <td>0.045093</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[10  8  7  3 13 14  4]</td>\n      <td>3.324612</td>\n      <td>0.79449296</td>\n      <td>8257</td>\n      <td>7</td>\n      <td>-0.010811</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[10  8  7  3 13 14  4  6]</td>\n      <td>3.198178</td>\n      <td>0.8897255</td>\n      <td>9230</td>\n      <td>8</td>\n      <td>0.095233</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[10  8  7  3 13 14  4  6 12]</td>\n      <td>3.225396</td>\n      <td>0.94224745</td>\n      <td>10203</td>\n      <td>9</td>\n      <td>0.052522</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[10  8  7  3 13 14  4  6 12  5]</td>\n      <td>3.316229</td>\n      <td>0.9477945</td>\n      <td>11176</td>\n      <td>10</td>\n      <td>0.005547</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15]</td>\n      <td>3.269594</td>\n      <td>0.9539246</td>\n      <td>12149</td>\n      <td>11</td>\n      <td>0.006130</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1]</td>\n      <td>3.351904</td>\n      <td>0.96037114</td>\n      <td>13122</td>\n      <td>12</td>\n      <td>0.006447</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2]</td>\n      <td>4.396824</td>\n      <td>0.974397</td>\n      <td>14095</td>\n      <td>13</td>\n      <td>0.014026</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11]</td>\n      <td>4.056553</td>\n      <td>0.98134327</td>\n      <td>15068</td>\n      <td>14</td>\n      <td>0.006946</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]</td>\n      <td>3.805976</td>\n      <td>0.98117673</td>\n      <td>16041</td>\n      <td>15</td>\n      <td>-0.000167</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "delta의 변화를 보자\n",
    "가장 변화율이 높은순으로 정렬하면 다음과 같다.\n",
    "\n",
    "feature 3이 feature 선택시 정확도가 올라가는 것을 확인할 수 있다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       combination      time    accuracy  \\\n2                                    [10  8  7  3]  3.164358   0.7413879   \n5                        [10  8  7  3 13 14  4  6]  3.198178   0.8897255   \n6                                       [10  8  7]  3.156260   0.6394423   \n7                                          [10  8]  3.146891   0.5692297   \n11                    [10  8  7  3 13 14  4  6 12]  3.225396  0.94224745   \n13                             [10  8  7  3 13 14]  3.177221   0.8053038   \n12                                [10  8  7  3 13]  3.179360   0.7602112   \n1         [10  8  7  3 13 14  4  6 12  5 15  1  2]  4.396824    0.974397   \n10     [10  8  7  3 13 14  4  6 12  5 15  1  2 11]  4.056553  0.98134327   \n0            [10  8  7  3 13 14  4  6 12  5 15  1]  3.351904  0.96037114   \n14              [10  8  7  3 13 14  4  6 12  5 15]  3.269594   0.9539246   \n4                  [10  8  7  3 13 14  4  6 12  5]  3.316229   0.9477945   \n9                                             [10]  3.915419  0.50194895   \n8   [10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]  3.805976  0.98117673   \n3                           [10  8  7  3 13 14  4]  3.324612  0.79449296   \n\n   param_size feature_selected     delta  feature  acc_per_one  \n2        5338                4  0.101946        3     0.423241  \n5        9230                8  0.095233        6     0.373884  \n6        4365                3  0.070213        7     0.480694  \n7        3392                2  0.067281        8     0.484225  \n11      10203                9  0.052522       12     0.366505  \n13       7284                6  0.045093       14     0.408649  \n12       6311                5  0.018823       13     0.423124  \n1       14095               13  0.014026        2     0.249850  \n10      15068               14  0.006946       11     0.228911  \n0       13122               12  0.006447        1     0.280500  \n14      12149               11  0.006130       15     0.354344  \n4       11176               10  0.005547        5     0.356626  \n9        2419                1  0.000000       10     0.501949  \n8       16041               15 -0.000167        9     0.098697  \n3        8257                7 -0.010811        4     0.383396  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n      <th>delta</th>\n      <th>feature</th>\n      <th>acc_per_one</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>[10  8  7  3]</td>\n      <td>3.164358</td>\n      <td>0.7413879</td>\n      <td>5338</td>\n      <td>4</td>\n      <td>0.101946</td>\n      <td>3</td>\n      <td>0.423241</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[10  8  7  3 13 14  4  6]</td>\n      <td>3.198178</td>\n      <td>0.8897255</td>\n      <td>9230</td>\n      <td>8</td>\n      <td>0.095233</td>\n      <td>6</td>\n      <td>0.373884</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[10  8  7]</td>\n      <td>3.156260</td>\n      <td>0.6394423</td>\n      <td>4365</td>\n      <td>3</td>\n      <td>0.070213</td>\n      <td>7</td>\n      <td>0.480694</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[10  8]</td>\n      <td>3.146891</td>\n      <td>0.5692297</td>\n      <td>3392</td>\n      <td>2</td>\n      <td>0.067281</td>\n      <td>8</td>\n      <td>0.484225</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[10  8  7  3 13 14  4  6 12]</td>\n      <td>3.225396</td>\n      <td>0.94224745</td>\n      <td>10203</td>\n      <td>9</td>\n      <td>0.052522</td>\n      <td>12</td>\n      <td>0.366505</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[10  8  7  3 13 14]</td>\n      <td>3.177221</td>\n      <td>0.8053038</td>\n      <td>7284</td>\n      <td>6</td>\n      <td>0.045093</td>\n      <td>14</td>\n      <td>0.408649</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[10  8  7  3 13]</td>\n      <td>3.179360</td>\n      <td>0.7602112</td>\n      <td>6311</td>\n      <td>5</td>\n      <td>0.018823</td>\n      <td>13</td>\n      <td>0.423124</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2]</td>\n      <td>4.396824</td>\n      <td>0.974397</td>\n      <td>14095</td>\n      <td>13</td>\n      <td>0.014026</td>\n      <td>2</td>\n      <td>0.249850</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11]</td>\n      <td>4.056553</td>\n      <td>0.98134327</td>\n      <td>15068</td>\n      <td>14</td>\n      <td>0.006946</td>\n      <td>11</td>\n      <td>0.228911</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1]</td>\n      <td>3.351904</td>\n      <td>0.96037114</td>\n      <td>13122</td>\n      <td>12</td>\n      <td>0.006447</td>\n      <td>1</td>\n      <td>0.280500</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15]</td>\n      <td>3.269594</td>\n      <td>0.9539246</td>\n      <td>12149</td>\n      <td>11</td>\n      <td>0.006130</td>\n      <td>15</td>\n      <td>0.354344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[10  8  7  3 13 14  4  6 12  5]</td>\n      <td>3.316229</td>\n      <td>0.9477945</td>\n      <td>11176</td>\n      <td>10</td>\n      <td>0.005547</td>\n      <td>5</td>\n      <td>0.356626</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[10]</td>\n      <td>3.915419</td>\n      <td>0.50194895</td>\n      <td>2419</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>0.501949</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]</td>\n      <td>3.805976</td>\n      <td>0.98117673</td>\n      <td>16041</td>\n      <td>15</td>\n      <td>-0.000167</td>\n      <td>9</td>\n      <td>0.098697</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[10  8  7  3 13 14  4]</td>\n      <td>3.324612</td>\n      <td>0.79449296</td>\n      <td>8257</td>\n      <td>7</td>\n      <td>-0.010811</td>\n      <td>4</td>\n      <td>0.383396</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_one.sort_values(by='delta', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "피쳐 정보를 추가한다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "table_for_one.loc[:, 'feature'] = table_for_one.loc[:, 'combination'].apply(\n",
    "    lambda x: np.fromstring(x.lstrip('[').rstrip(']'), sep=' ', dtype='int')[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       combination      time    accuracy  \\\n11           [10  8  7  3 13 14  4  6 12  5 15  1]  3.351904  0.96037114   \n12        [10  8  7  3 13 14  4  6 12  5 15  1  2]  4.396824    0.974397   \n3                                    [10  8  7  3]  3.164358   0.7413879   \n6                           [10  8  7  3 13 14  4]  3.324612  0.79449296   \n9                  [10  8  7  3 13 14  4  6 12  5]  3.316229   0.9477945   \n7                        [10  8  7  3 13 14  4  6]  3.198178   0.8897255   \n2                                       [10  8  7]  3.156260   0.6394423   \n1                                          [10  8]  3.146891   0.5692297   \n14  [10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]  3.805976  0.98117673   \n0                                             [10]  3.915419  0.50194895   \n13     [10  8  7  3 13 14  4  6 12  5 15  1  2 11]  4.056553  0.98134327   \n8                     [10  8  7  3 13 14  4  6 12]  3.225396  0.94224745   \n4                                 [10  8  7  3 13]  3.179360   0.7602112   \n5                              [10  8  7  3 13 14]  3.177221   0.8053038   \n10              [10  8  7  3 13 14  4  6 12  5 15]  3.269594   0.9539246   \n\n   param_size feature_selected     delta  feature  \n11      13122               12  0.006447        1  \n12      14095               13  0.014026        2  \n3        5338                4  0.101946        3  \n6        8257                7 -0.010811        4  \n9       11176               10  0.005547        5  \n7        9230                8  0.095233        6  \n2        4365                3  0.070213        7  \n1        3392                2  0.067281        8  \n14      16041               15 -0.000167        9  \n0        2419                1  0.000000       10  \n13      15068               14  0.006946       11  \n8       10203                9  0.052522       12  \n4        6311                5  0.018823       13  \n5        7284                6  0.045093       14  \n10      12149               11  0.006130       15  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n      <th>delta</th>\n      <th>feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1]</td>\n      <td>3.351904</td>\n      <td>0.96037114</td>\n      <td>13122</td>\n      <td>12</td>\n      <td>0.006447</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2]</td>\n      <td>4.396824</td>\n      <td>0.974397</td>\n      <td>14095</td>\n      <td>13</td>\n      <td>0.014026</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[10  8  7  3]</td>\n      <td>3.164358</td>\n      <td>0.7413879</td>\n      <td>5338</td>\n      <td>4</td>\n      <td>0.101946</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[10  8  7  3 13 14  4]</td>\n      <td>3.324612</td>\n      <td>0.79449296</td>\n      <td>8257</td>\n      <td>7</td>\n      <td>-0.010811</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[10  8  7  3 13 14  4  6 12  5]</td>\n      <td>3.316229</td>\n      <td>0.9477945</td>\n      <td>11176</td>\n      <td>10</td>\n      <td>0.005547</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[10  8  7  3 13 14  4  6]</td>\n      <td>3.198178</td>\n      <td>0.8897255</td>\n      <td>9230</td>\n      <td>8</td>\n      <td>0.095233</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[10  8  7]</td>\n      <td>3.156260</td>\n      <td>0.6394423</td>\n      <td>4365</td>\n      <td>3</td>\n      <td>0.070213</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[10  8]</td>\n      <td>3.146891</td>\n      <td>0.5692297</td>\n      <td>3392</td>\n      <td>2</td>\n      <td>0.067281</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]</td>\n      <td>3.805976</td>\n      <td>0.98117673</td>\n      <td>16041</td>\n      <td>15</td>\n      <td>-0.000167</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>[10]</td>\n      <td>3.915419</td>\n      <td>0.50194895</td>\n      <td>2419</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11]</td>\n      <td>4.056553</td>\n      <td>0.98134327</td>\n      <td>15068</td>\n      <td>14</td>\n      <td>0.006946</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[10  8  7  3 13 14  4  6 12]</td>\n      <td>3.225396</td>\n      <td>0.94224745</td>\n      <td>10203</td>\n      <td>9</td>\n      <td>0.052522</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[10  8  7  3 13]</td>\n      <td>3.179360</td>\n      <td>0.7602112</td>\n      <td>6311</td>\n      <td>5</td>\n      <td>0.018823</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[10  8  7  3 13 14]</td>\n      <td>3.177221</td>\n      <td>0.8053038</td>\n      <td>7284</td>\n      <td>6</td>\n      <td>0.045093</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15]</td>\n      <td>3.269594</td>\n      <td>0.9539246</td>\n      <td>12149</td>\n      <td>11</td>\n      <td>0.006130</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_one = table_for_one.sort_values(by='feature')\n",
    "table_for_one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "하나의 피쳐만 선택했을때 정확도를 붙여보자"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [],
   "source": [
    "one_feature_table = table[table['feature_selected'] == 1]\n",
    "\n",
    "for idx, acc_per_one in enumerate(one_feature_table.loc[:, 'accuracy'].apply(lambda x: np.array(x, dtype=np.float64))):\n",
    "    table_for_one.loc[idx, 'acc_per_one'] = acc_per_one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       combination      time    accuracy  \\\n0            [10  8  7  3 13 14  4  6 12  5 15  1]  3.351904  0.96037114   \n1         [10  8  7  3 13 14  4  6 12  5 15  1  2]  4.396824    0.974397   \n2                                    [10  8  7  3]  3.164358   0.7413879   \n3                           [10  8  7  3 13 14  4]  3.324612  0.79449296   \n4                  [10  8  7  3 13 14  4  6 12  5]  3.316229   0.9477945   \n5                        [10  8  7  3 13 14  4  6]  3.198178   0.8897255   \n6                                       [10  8  7]  3.156260   0.6394423   \n7                                          [10  8]  3.146891   0.5692297   \n8   [10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]  3.805976  0.98117673   \n9                                             [10]  3.915419  0.50194895   \n10     [10  8  7  3 13 14  4  6 12  5 15  1  2 11]  4.056553  0.98134327   \n11                    [10  8  7  3 13 14  4  6 12]  3.225396  0.94224745   \n12                                [10  8  7  3 13]  3.179360   0.7602112   \n13                             [10  8  7  3 13 14]  3.177221   0.8053038   \n14              [10  8  7  3 13 14  4  6 12  5 15]  3.269594   0.9539246   \n\n   param_size feature_selected     delta  feature  acc_per_one  \n0       13122               12  0.006447        1     0.280500  \n1       14095               13  0.014026        2     0.249850  \n2        5338                4  0.101946        3     0.423241  \n3        8257                7 -0.010811        4     0.383396  \n4       11176               10  0.005547        5     0.356626  \n5        9230                8  0.095233        6     0.373884  \n6        4365                3  0.070213        7     0.480694  \n7        3392                2  0.067281        8     0.484225  \n8       16041               15 -0.000167        9     0.098697  \n9        2419                1  0.000000       10     0.501949  \n10      15068               14  0.006946       11     0.228911  \n11      10203                9  0.052522       12     0.366505  \n12       6311                5  0.018823       13     0.423124  \n13       7284                6  0.045093       14     0.408649  \n14      12149               11  0.006130       15     0.354344  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combination</th>\n      <th>time</th>\n      <th>accuracy</th>\n      <th>param_size</th>\n      <th>feature_selected</th>\n      <th>delta</th>\n      <th>feature</th>\n      <th>acc_per_one</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1]</td>\n      <td>3.351904</td>\n      <td>0.96037114</td>\n      <td>13122</td>\n      <td>12</td>\n      <td>0.006447</td>\n      <td>1</td>\n      <td>0.280500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2]</td>\n      <td>4.396824</td>\n      <td>0.974397</td>\n      <td>14095</td>\n      <td>13</td>\n      <td>0.014026</td>\n      <td>2</td>\n      <td>0.249850</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[10  8  7  3]</td>\n      <td>3.164358</td>\n      <td>0.7413879</td>\n      <td>5338</td>\n      <td>4</td>\n      <td>0.101946</td>\n      <td>3</td>\n      <td>0.423241</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[10  8  7  3 13 14  4]</td>\n      <td>3.324612</td>\n      <td>0.79449296</td>\n      <td>8257</td>\n      <td>7</td>\n      <td>-0.010811</td>\n      <td>4</td>\n      <td>0.383396</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[10  8  7  3 13 14  4  6 12  5]</td>\n      <td>3.316229</td>\n      <td>0.9477945</td>\n      <td>11176</td>\n      <td>10</td>\n      <td>0.005547</td>\n      <td>5</td>\n      <td>0.356626</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[10  8  7  3 13 14  4  6]</td>\n      <td>3.198178</td>\n      <td>0.8897255</td>\n      <td>9230</td>\n      <td>8</td>\n      <td>0.095233</td>\n      <td>6</td>\n      <td>0.373884</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[10  8  7]</td>\n      <td>3.156260</td>\n      <td>0.6394423</td>\n      <td>4365</td>\n      <td>3</td>\n      <td>0.070213</td>\n      <td>7</td>\n      <td>0.480694</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[10  8]</td>\n      <td>3.146891</td>\n      <td>0.5692297</td>\n      <td>3392</td>\n      <td>2</td>\n      <td>0.067281</td>\n      <td>8</td>\n      <td>0.484225</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11  9]</td>\n      <td>3.805976</td>\n      <td>0.98117673</td>\n      <td>16041</td>\n      <td>15</td>\n      <td>-0.000167</td>\n      <td>9</td>\n      <td>0.098697</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[10]</td>\n      <td>3.915419</td>\n      <td>0.50194895</td>\n      <td>2419</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>0.501949</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15  1  2 11]</td>\n      <td>4.056553</td>\n      <td>0.98134327</td>\n      <td>15068</td>\n      <td>14</td>\n      <td>0.006946</td>\n      <td>11</td>\n      <td>0.228911</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[10  8  7  3 13 14  4  6 12]</td>\n      <td>3.225396</td>\n      <td>0.94224745</td>\n      <td>10203</td>\n      <td>9</td>\n      <td>0.052522</td>\n      <td>12</td>\n      <td>0.366505</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[10  8  7  3 13]</td>\n      <td>3.179360</td>\n      <td>0.7602112</td>\n      <td>6311</td>\n      <td>5</td>\n      <td>0.018823</td>\n      <td>13</td>\n      <td>0.423124</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[10  8  7  3 13 14]</td>\n      <td>3.177221</td>\n      <td>0.8053038</td>\n      <td>7284</td>\n      <td>6</td>\n      <td>0.045093</td>\n      <td>14</td>\n      <td>0.408649</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[10  8  7  3 13 14  4  6 12  5 15]</td>\n      <td>3.269594</td>\n      <td>0.9539246</td>\n      <td>12149</td>\n      <td>11</td>\n      <td>0.006130</td>\n      <td>15</td>\n      <td>0.354344</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "accuracy = table_for_one.loc[:, 'accuracy'].apply(lambda x: np.array(x, dtype=np.float64)).tolist()\n",
    "acc_per_one = table_for_one.loc[:, 'acc_per_one'].tolist()\n",
    "delta = table_for_one.loc[:, 'delta'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 최대로 성능이 좋은 10 feature와 조합을 해보자"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### delta와 상관관계가 있을까?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "outputs": [
    {
     "data": {
      "text/plain": "       delta  feature  acc_per_one\n2   0.101946        3     0.423241\n5   0.095233        6     0.373884\n6   0.070213        7     0.480694\n7   0.067281        8     0.484225\n11  0.052522       12     0.366505\n13  0.045093       14     0.408649\n12  0.018823       13     0.423124\n1   0.014026        2     0.249850\n10  0.006946       11     0.228911\n0   0.006447        1     0.280500\n14  0.006130       15     0.354344\n4   0.005547        5     0.356626\n9   0.000000       10     0.501949\n8  -0.000167        9     0.098697\n3  -0.010811        4     0.383396",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>delta</th>\n      <th>feature</th>\n      <th>acc_per_one</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.101946</td>\n      <td>3</td>\n      <td>0.423241</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.095233</td>\n      <td>6</td>\n      <td>0.373884</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.070213</td>\n      <td>7</td>\n      <td>0.480694</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.067281</td>\n      <td>8</td>\n      <td>0.484225</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.052522</td>\n      <td>12</td>\n      <td>0.366505</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.045093</td>\n      <td>14</td>\n      <td>0.408649</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.018823</td>\n      <td>13</td>\n      <td>0.423124</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.014026</td>\n      <td>2</td>\n      <td>0.249850</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.006946</td>\n      <td>11</td>\n      <td>0.228911</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.006447</td>\n      <td>1</td>\n      <td>0.280500</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.006130</td>\n      <td>15</td>\n      <td>0.354344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005547</td>\n      <td>5</td>\n      <td>0.356626</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>0.501949</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.000167</td>\n      <td>9</td>\n      <td>0.098697</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.010811</td>\n      <td>4</td>\n      <td>0.383396</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_3 = table_for_one.loc[:, ['delta', 'feature', 'acc_per_one']].sort_values(by='delta', ascending=False)\n",
    "experiment_3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "다음 표에 의하면 feature 3, 6, 7, 8 ... 순으로 변화가 큰 피쳐이다.\n",
    "그러면 가장 성능이 좋았던 feature 10과 조합을 했을 때 정확도 변화는 얼만큼 될 것인가"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.7625816250001662, array(0.66319627, dtype=float32), 3392)"
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_time, acc, param_size = layer_3_define([10, 3])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "data": {
      "text/plain": "(5.073646832999657, array(0.63664377, dtype=float32), 3392)"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_time, acc, param_size = layer_3_define([10, 6])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.8463717499998893, array(0.57807505, dtype=float32), 3392)"
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_time, acc, param_size = layer_3_define([10, 7])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.846786833999431, array(0.5692297, dtype=float32), 3392)"
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "단순 개별 피쳐의 정확도가 높은 순서대로 정렬시 10 다음으로 선택은 8이다.\n",
    "'''\n",
    "calc_time, acc, param_size = layer_3_define([10, 8])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.5060658749998765, array(0.64164114, dtype=float32), 3392)"
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "그런데 12는 8보다 델타가 떨어지는데 정확도가 오히려 높다.\n",
    "'''\n",
    "calc_time, acc, param_size = layer_3_define([10, 12])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.7210196659998473, array(0.6434402, dtype=float32), 3392)"
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_time, acc, param_size = layer_3_define([10, 14])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.9162809590006873, array(0.6015625, dtype=float32), 3392)"
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_time, acc, param_size = layer_3_define([10, 13])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.776294332999896, array(0.5019323, dtype=float32), 3392)"
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "개별 피쳐로 봤을 때 가장 낮은 피쳐와 조합하면 제일 최하 결과가 나오는 것을 볼 수 있다.\n",
    "'''\n",
    "calc_time, acc, param_size = layer_3_define([10, 9])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.931817000000592, array(0.66511196, dtype=float32), 3392)"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "델타가 가장 낮은 피쳐를 조합하면 오히려 정확도가 가장 높음\n",
    "'''\n",
    "calc_time, acc, param_size = layer_3_define([10, 4])\n",
    "calc_time, acc, param_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Feature 1개만 선택해서 나온 결과를 정확도 내림차순으로 정렬해서 나온 가장 큰 피쳐를 첫번째로 배정하고\n",
    "feature 1개, 2개, …, N개 피쳐로 추론했을때, 피쳐의 변화도 acc(n+1) - acc(n) 를 내림차순해서 가장 변화도가 큰 피쳐를 하나씩 선택했을 때 정확도는 높게 나온다\n",
    "그런데 완전한 비례관계가 통용되지 않는다.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[43mexperiment_3\u001B[49m[experiment_3[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m10\u001B[39m]\u001B[38;5;241m.\u001B[39mfeature\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[1;32m      4\u001B[0m     calc_time, acc, param_size \u001B[38;5;241m=\u001B[39m layer_3_define([\u001B[38;5;241m10\u001B[39m, feature])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'experiment_3' is not defined"
     ]
    }
   ],
   "source": [
    "features = experiment_3[experiment_3['feature'] != 10].feature.tolist()\n",
    "\n",
    "for feature in features:\n",
    "    calc_time, acc, param_size = layer_3_define([10, feature])\n",
    "    print([10, feature], calc_time, acc, param_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "결과를 보면 오히려 [10, 15]에서 높은 걸 볼 수 있다.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 개별 정확도가 높은 순으로 조합을 해봄"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [07:49<00:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.350895216700155, 3.326317679200474, 3.270415045699701, 3.471186595600011, 3.482333720999668, 3.2403977624999243, 3.245336166400011, 3.539594525200118, 3.279852958099582, 3.350847891900048, 3.309964141599994, 3.3215255210001486, 3.2723522708005475, 3.4136360875998433]\n",
      "[0.5692297220230103, 0.5780750513076782, 0.6631962656974792, 0.6015625, 0.6434401869773865, 0.6651119589805603, 0.6366437673568726, 0.6416411399841309, 0.640108585357666, 0.670059323310852, 0.6083089113235474, 0.3960387706756592, 0.5629497766494751, 0.5019323229789734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = experiment_3[experiment_3['feature'] != 10].sort_values(by='acc_per_one', ascending=False).feature.tolist()\n",
    "avg_time = [0] * len(features)\n",
    "avg_acc = [0] * len(features)\n",
    "\n",
    "with tqdm(total = len(features) * 10) as pbar:\n",
    "    for _ in range(10):\n",
    "        for idx, feature in enumerate(features):\n",
    "            calc_time, acc, param_size = layer_3_define([10, feature])\n",
    "            avg_time[idx] += calc_time\n",
    "            avg_acc[idx] += acc\n",
    "            # print([10, feature], calc_time, acc, param_size)\n",
    "            pbar.update(1)\n",
    "\n",
    "    avg_time = list(map(lambda x: x / 10, avg_time))\n",
    "    avg_acc = list(map(lambda x: x / 10, avg_acc))\n",
    "    print(avg_time)\n",
    "    print(avg_acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "data": {
      "text/plain": "[3.350895216700155,\n 3.326317679200474,\n 3.270415045699701,\n 3.471186595600011,\n 3.482333720999668,\n 3.2403977624999243,\n 3.245336166400011,\n 3.539594525200118,\n 3.279852958099582,\n 3.350847891900048,\n 3.309964141599994,\n 3.3215255210001486,\n 3.2723522708005475,\n 3.4136360875998433]"
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.5692297220230103,\n 0.5780750513076782,\n 0.6631962656974792,\n 0.6015625,\n 0.6434401869773865,\n 0.6651119589805603,\n 0.6366437673568726,\n 0.6416411399841309,\n 0.640108585357666,\n 0.670059323310852,\n 0.6083089113235474,\n 0.3960387706756592,\n 0.5629497766494751,\n 0.5019323229789734]"
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 개별 정확도가 낮은 순으로 조합해봄"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "([9, 10], 3.1908108750012616, 0.5019323229789734, 3392): 100%|██████████| 140/140 [07:40<00:00,  3.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3638296166001966, 3.237301891800416, 3.2639675375003208, 3.257037479000064, 3.274048187700282, 3.4723227709995625, 3.3244284541000524, 3.3534752038998703, 3.2993868080999165, 3.2928509998999287, 3.2280949166002757, 3.2163316208996546, 3.2393365625001023, 3.2270457252001505]\n",
      "[0.22889459133148193, 0.24996668100357056, 0.27926772832870483, 0.35569363832473755, 0.3566264510154724, 0.36820361018180847, 0.37509995698928833, 0.38457822799682617, 0.40881529450416565, 0.4236573874950409, 0.4257396161556244, 0.4807436168193817, 0.4840584993362427, 0.5019323229789734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = experiment_3[experiment_3['feature'] != 9].sort_values(by='acc_per_one').feature.tolist()\n",
    "\n",
    "avg_time_2 = [0] * len(features)\n",
    "avg_acc_2 = [0] * len(features)\n",
    "\n",
    "with tqdm(total = len(features) * 10) as pbar:\n",
    "    for _ in range(10):\n",
    "        for idx, feature in enumerate(features):\n",
    "            calc_time, acc, param_size = layer_3_define([9, feature])\n",
    "            avg_time_2[idx] += calc_time\n",
    "            avg_acc_2[idx] += acc\n",
    "            pbar.set_description(f'{[9, feature], calc_time, acc, param_size}')\n",
    "            pbar.update(1)\n",
    "\n",
    "    avg_time_2 = list(map(lambda x: x / 10, avg_time_2))\n",
    "    avg_acc_2 = list(map(lambda x: x / 10, avg_acc_2))\n",
    "    print(avg_time_2)\n",
    "    print(avg_acc_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "가장 정확도가 낮은 피쳐는 선택하지 않아도 괜찮음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실험 3. 전체 레이어에서 feature 1개만 제거함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [
    {
     "data": {
      "text/plain": "(3.993391291001899, 0.9215751886367798, 10085)"
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channel_one = 1\n",
    "kernel_size = 3\n",
    "device = \"cpu\"\n",
    "\n",
    "def layer_define(in_channel, comb_one, comb_two, comb_three):\n",
    "    torch.manual_seed(888)\n",
    "    np.random.seed(888)\n",
    "    random.seed(888)\n",
    "\n",
    "    layer_1_out = len(comb_one)\n",
    "    layer_1 = cnn_layer_x(in_channel, layer_1_out, kernel_size,\n",
    "                          model.feature_extractor.layer1.conv.weight.to(device)[comb_one],\n",
    "                          model.feature_extractor.layer1.conv.bias.to(device)[comb_one])\n",
    "\n",
    "    layer_2_out = len(comb_two)\n",
    "    layer_2 = cnn_layer_x(layer_1_out, layer_2_out, kernel_size,\n",
    "                          model.feature_extractor.layer2.conv.weight.to(device)[comb_two][:, comb_one],\n",
    "                          model.feature_extractor.layer2.conv.bias.to(device)[comb_two])\n",
    "\n",
    "    layer_3_out = len(comb_three)\n",
    "    layer_3 = cnn_layer_x(layer_2_out, layer_3_out, kernel_size,\n",
    "                          model.feature_extractor.layer3.conv.weight.to(device)[comb_three][:, comb_two],\n",
    "                          model.feature_extractor.layer3.conv.bias.to(device)[comb_three])\n",
    "\n",
    "    res_flatten_idx = list(reduce(lambda res, e: res + e,\n",
    "                                  map(lambda x: [i + (3 * 3) * x for i in range(3 * 3)], comb_three)))\n",
    "\n",
    "    params_size  = in_channel  * layer_1_out * kernel_size * kernel_size + layer_1_out\n",
    "    params_size += layer_1_out * layer_2_out * kernel_size * kernel_size + layer_2_out\n",
    "    params_size += layer_2_out * layer_3_out * kernel_size * kernel_size + layer_3_out\n",
    "    params_size += len(res_flatten_idx) * 100 + 100 + 100 * 10 + 10\n",
    "\n",
    "    classifier = nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('in_linear', nn.Linear(layer_3_out * kernel_size * kernel_size, 100)),\n",
    "            ('relu', nn.ReLU(inplace=True)),\n",
    "            ('out_linear', nn.Linear(100, 10)),\n",
    "            ('output', nn.Softmax(dim=0))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    classifier.in_linear.weight = nn.Parameter(model.classifier.in_linear.weight[:, res_flatten_idx])\n",
    "    classifier.in_linear.bias = nn.Parameter(model.classifier.in_linear.bias)\n",
    "    classifier.out_linear.weight = nn.Parameter(model.classifier.out_linear.weight)\n",
    "    classifier.out_linear.bias = nn.Parameter(model.classifier.out_linear.bias)\n",
    "\n",
    "    modified_model = nn.Sequential(layer_1, layer_2, layer_3, classifier)\n",
    "    start = time.perf_counter()\n",
    "    res = eval_loop(modified_model, train_dataloader)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    return end - start, res.detach().cpu().numpy().tolist(), params_size\n",
    "\n",
    "# 12687 / 17014 74.5% 0.95\n",
    "# 10922 / 17014 64.2% 0.9517\n",
    "layer_define(1,\n",
    "             [0, 1, 2, 3],\n",
    "             [0, 1, 2, 3, 4, 5, 6],\n",
    "             [1, 2, 3, 5, 6, 7, 8, 10, 15])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "# 0\n",
    "# 1\n",
    "# 2\n",
    "# ...\n",
    "# 10\n",
    "# 10 -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 0.863322913646698     3\n",
    "# 0.9244070053100586    4\n",
    "# 0.9409481883049011    5\n",
    "# 0.9412813186645508    6\n",
    "# 0.9528084993362427    7\n",
    "# 0.9571728706359863    8 59.9%\n",
    "# 0.9646355509757996    9 65.7%\n",
    "# 0.9687166810035706   10 71.4%\n",
    "# 0.9729310870170593   11 77.1%\n",
    "# 0.9785114526748657   12 82.8%\n",
    "# 0.9813432693481445   13 88.5%\n",
    "# 0.9811767339706421   14 94.3%\n",
    "# 0.9820762276649475   15 100%\n",
    "# print(layer_3_define([10] + [15] + [14] + [12] + [3] + [8] + [7] + [1] + [5] + [11] + [13] + [2] + [6] + [4] + [0] + [9]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def find_best_feature_in_select(layer_searching, define_item, candidates):\n",
    "    select_list = [] + define_item\n",
    "    select_item = None\n",
    "    prev_acc = 0\n",
    "\n",
    "    candidates = [item for item in candidates if item not in select_list]\n",
    "\n",
    "    logs = ''\n",
    "\n",
    "    while len(select_list) != (len(candidates) + len(define_item)):\n",
    "        for cand in candidates:\n",
    "            if cand in select_list:\n",
    "                continue\n",
    "\n",
    "            calc_time, acc, param_size = layer_searching(select_list + [cand])\n",
    "\n",
    "            if prev_acc < acc:\n",
    "                print(calc_time, acc, param_size)\n",
    "                logs += f'{calc_time}, {acc}, {param_size}\\n'\n",
    "                prev_acc = acc\n",
    "                select_item = cand\n",
    "\n",
    "        select_list += [select_item]\n",
    "        logs += f'{str(select_list)}\\n'\n",
    "        print(select_list)\n",
    "\n",
    "    with open(f'./{layer_searching.__name__}_first-{define_item}.txt', 'w') as f:\n",
    "        f.write(logs)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.759977708000065 0.47288113832473755 3392\n",
      "2.931562750000012 0.5355976819992065 3392\n",
      "2.8892718329999525 0.646172046661377 3392\n",
      "2.901777041999935 0.6512693166732788 3392\n",
      "[8, 14]\n",
      "2.9352537080000047 0.6702924966812134 4365\n",
      "2.929251749999935 0.7167843580245972 4365\n",
      "2.921331667000004 0.7697561383247375 4365\n",
      "2.9129052079999838 0.78767991065979 4365\n",
      "[8, 14, 6]\n",
      "3.0042745839999725 0.7919443249702454 5338\n",
      "2.988961207999978 0.8412846326828003 5338\n",
      "2.935044875000017 0.8609908223152161 5338\n",
      "[8, 14, 6, 12]\n",
      "2.958714332999989 0.8645555973052979 6311\n",
      "2.9411378329999707 0.9127298593521118 6311\n",
      "[8, 14, 6, 12, 3]\n",
      "2.959679416999961 0.914578914642334 7284\n",
      "2.955757042000073 0.932252824306488 7284\n",
      "2.9495299999999816 0.9355010390281677 7284\n",
      "[8, 14, 6, 12, 3, 7]\n",
      "2.978871457999958 0.9403485059738159 8257\n",
      "2.9713117920000514 0.9407482743263245 8257\n",
      "[8, 14, 6, 12, 3, 7, 15]\n",
      "3.007295959000089 0.9435134530067444 9230\n",
      "2.9861657079999304 0.9435467720031738 9230\n",
      "2.994738333999976 0.9495769143104553 9230\n",
      "2.9913870000000315 0.9523754119873047 9230\n",
      "[8, 14, 6, 12, 3, 7, 15, 10]\n",
      "2.9915134589999752 0.9528917670249939 10203\n",
      "2.992870999999923 0.9606709480285645 10203\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4]\n",
      "3.0239012499999944 0.9615038633346558 11176\n",
      "3.0211616249999906 0.962753176689148 11176\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11]\n",
      "3.0416854170000533 0.9632362723350525 12149\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11, 0]\n",
      "3.044380125000089 0.9634028673171997 13122\n",
      "3.032385917000056 0.9639692306518555 13122\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11, 0, 13]\n",
      "3.0550604999999678 0.9653018116950989 14095\n",
      "3.0846668329999147 0.9662513136863708 14095\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11, 0, 13, 5]\n",
      "3.064538500000026 0.9792277216911316 15068\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11, 0, 13, 5, 2]\n",
      "3.083858208000038 0.9819929599761963 16041\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11, 0, 13, 5, 2, 1]\n",
      "3.113279415999955 0.9820762276649475 17014\n",
      "[8, 14, 6, 12, 3, 7, 15, 10, 4, 11, 0, 13, 5, 2, 1, 9]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "find_best_feature_in_select(layer_3_define, [8], list(range(16)))\n",
    "'''\n",
    "find_best_feature_in_select(layer_3_define, [8], list(range(16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.493162916000074 0.5006330013275146 3392\n",
      "3.133641207999972 0.5454757213592529 3392\n",
      "3.2835739170000124 0.6066098213195801 3392\n",
      "3.1593692500000543 0.6086587309837341 3392\n",
      "2.9427764580000257 0.6302138566970825 3392\n",
      "2.9366375829999924 0.6466051340103149 3392\n",
      "[7, 15]\n",
      "2.955303040999979 0.6578658223152161 4365\n",
      "2.9568848750000143 0.6672607660293579 4365\n",
      "2.9527675000001636 0.7413379549980164 4365\n",
      "2.9466790829999354 0.7447694540023804 4365\n",
      "[7, 15, 8]\n",
      "2.9963104580001527 0.7506163120269775 5338\n",
      "2.9926391249998687 0.7699393630027771 5338\n",
      "2.9755909580001116 0.81739741563797 5338\n",
      "2.969754250000051 0.8366870880126953 5338\n",
      "[7, 15, 8, 5]\n",
      "3.0001310410000315 0.8460654020309448 6311\n",
      "3.0051153750000594 0.8555936813354492 6311\n",
      "2.9932984580000266 0.8649386763572693 6311\n",
      "2.986236957999836 0.8740338683128357 6311\n",
      "2.982602750000069 0.8889925479888916 6311\n",
      "[7, 15, 8, 5, 14]\n",
      "3.014801084000055 0.892307460308075 7284\n",
      "3.0331695410000066 0.9051172733306885 7284\n",
      "3.000720415999922 0.9136793613433838 7284\n",
      "3.0037436669999806 0.9307869076728821 7284\n",
      "[7, 15, 8, 5, 14, 12]\n",
      "3.044219249999969 0.9354677796363831 8257\n",
      "3.0305745420000676 0.9383329153060913 8257\n",
      "3.0295081250001203 0.9443296790122986 8257\n",
      "[7, 15, 8, 5, 14, 12, 10]\n",
      "3.0611892500000977 0.9456789493560791 9230\n",
      "3.0398612499998308 0.9491104483604431 9230\n",
      "3.0678035419996377 0.9500433206558228 9230\n",
      "3.0490465419998145 0.9527918696403503 9230\n",
      "3.044774791999771 0.9558901786804199 9230\n",
      "[7, 15, 8, 5, 14, 12, 10, 11]\n",
      "3.0799241250001614 0.956339955329895 10203\n",
      "3.064363874999799 0.957072913646698 10203\n",
      "3.067961582999942 0.9617037773132324 10203\n",
      "3.1344307090002985 0.9670342206954956 10203\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13]\n",
      "3.1112755419999303 0.9682835936546326 11176\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0]\n",
      "3.213241999999809 0.9685834050178528 12149\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0, 3]\n",
      "3.1362922499997694 0.9698994159698486 13122\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0, 3, 1]\n",
      "3.1475653749998855 0.9748467206954956 14095\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0, 3, 1, 2]\n",
      "3.1504366660001324 0.9789612293243408 15068\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0, 3, 1, 2, 6]\n",
      "3.814939417000005 0.9819929599761963 16041\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0, 3, 1, 2, 6, 4]\n",
      "3.3278442499999983 0.9820762276649475 17014\n",
      "[7, 15, 8, 5, 14, 12, 10, 11, 13, 0, 3, 1, 2, 6, 4, 9]\n",
      "3.146290790999956 0.5006330013275146 3392\n",
      "3.0450926660000732 0.5454757213592529 3392\n",
      "2.960793959000057 0.6066098213195801 3392\n",
      "2.9698322079998434 0.6086587309837341 3392\n",
      "2.9840711249999003 0.6302138566970825 3392\n",
      "2.966113250000035 0.6466051340103149 3392\n",
      "[7, 15]\n",
      "3.0312507919998097 0.6578658223152161 4365\n",
      "3.0976555420002114 0.6672607660293579 4365\n",
      "2.985080165999989 0.7413379549980164 4365\n",
      "2.97700737499963 0.7447694540023804 4365\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3.189259874999834 0.6466051340103149 3392\n",
    "[7, 15]\n",
    "'''\n",
    "%timeit find_best_feature_in_select(layer_3_define, [7], list(range(16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.507894166999904 0.15566697716712952 3392\n",
      "2.995962291000069 0.27926772832870483 3392\n",
      "2.895480624999891 0.4257396161556244 3392\n",
      "3.0365947500001766 0.4807436168193817 3392\n",
      "2.906769082999972 0.4840584993362427 3392\n",
      "2.925667665999981 0.5019323229789734 3392\n",
      "[9, 10]\n",
      "2.916017208000085 0.6067097783088684 4365\n",
      "2.922645915999965 0.6615971326828003 4365\n",
      "2.941887625000163 0.6669110059738159 4365\n",
      "2.9184901249998347 0.6698594093322754 4365\n",
      "[9, 10, 15]\n",
      "2.9611516669999673 0.6804537773132324 5338\n",
      "2.9421629159999156 0.748833954334259 5338\n",
      "2.954120750000129 0.763809323310852 5338\n",
      "2.941145332999895 0.7811000943183899 5338\n",
      "[9, 10, 15, 14]\n",
      "2.9482344999998986 0.8507795929908752 6311\n",
      "2.960098334000122 0.8621401786804199 6311\n",
      "[9, 10, 15, 14, 12]\n",
      "2.974797207999927 0.9240071773529053 7284\n",
      "[9, 10, 15, 14, 12, 3]\n",
      "2.993083749999869 0.9260727763175964 8257\n",
      "2.996783707999839 0.9406650066375732 8257\n",
      "[9, 10, 15, 14, 12, 3, 7]\n",
      "3.0013406250000116 0.9488106369972229 9230\n",
      "[9, 10, 15, 14, 12, 3, 7, 1]\n",
      "3.017225124999868 0.9531916379928589 10203\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8]\n",
      "3.0549324579999393 0.9576725959777832 11176\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5]\n",
      "3.062645624999959 0.9616870880126953 12149\n",
      "3.0821369169998434 0.963935911655426 12149\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5, 11]\n",
      "3.0782636250000905 0.9649020433425903 13122\n",
      "3.0602135419999286 0.968316912651062 13122\n",
      "3.0662456669999756 0.9690831303596497 13122\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5, 11, 13]\n",
      "3.1002863329999855 0.970432460308075 14095\n",
      "3.10091691599996 0.972831130027771 14095\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5, 11, 13, 2]\n",
      "3.719795041999987 0.9751465916633606 15068\n",
      "3.355535083000177 0.9787279963493347 15068\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5, 11, 13, 2, 6]\n",
      "3.5164474579999023 0.979044497013092 16041\n",
      "3.3285123339999245 0.9811767339706421 16041\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5, 11, 13, 2, 6, 4]\n",
      "3.323149457999989 0.9820762276649475 17014\n",
      "[9, 10, 15, 14, 12, 3, 7, 1, 8, 5, 11, 13, 2, 6, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "find_best_feature_in_select(layer_3_define, [9], list(range(16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.536726875000113 0.2734375 3392\n",
      "2.910618459000034 0.3896588385105133 3392\n",
      "2.8919654169999376 0.5022321343421936 3392\n",
      "2.8907044170000518 0.5172907710075378 3392\n",
      "2.8832434169999033 0.5354477763175964 3392\n",
      "2.8865759580003214 0.5629497766494751 3392\n",
      "[11, 10]\n",
      "2.9226562909998393 0.5898520946502686 4365\n",
      "2.9238179589997344 0.6525519490242004 4365\n",
      "2.900008957999944 0.7622767686843872 4365\n",
      "[11, 10, 3]\n",
      "3.0749532500003625 0.7726379036903381 5338\n",
      "2.951663499999995 0.8184801340103149 5338\n",
      "2.9369392089997746 0.8369203209877014 5338\n",
      "[11, 10, 3, 12]\n",
      "2.9714117920002536 0.8429337739944458 6311\n",
      "2.9628116250000858 0.8505796790122986 6311\n",
      "2.9989325410001584 0.8806303143501282 6311\n",
      "2.9657209160000093 0.8911247253417969 6311\n",
      "[11, 10, 3, 12, 14]\n",
      "3.0016404590001002 0.8932735919952393 7284\n",
      "3.1607307079998463 0.8959388136863708 7284\n",
      "3.0424065000001974 0.900702953338623 7284\n",
      "3.427970749999986 0.9167943596839905 7284\n",
      "[11, 10, 3, 12, 14, 5]\n",
      "3.0129503750004005 0.9194263219833374 8257\n",
      "3.0061898330000076 0.9251065850257874 8257\n",
      "3.000288458000341 0.9274719953536987 8257\n",
      "3.008871624999756 0.9366837739944458 8257\n",
      "3.0088478329998907 0.9385827779769897 8257\n",
      "[11, 10, 3, 12, 14, 5, 13]\n",
      "3.024621374999697 0.9419309496879578 9230\n",
      "3.0270853749998423 0.9439632296562195 9230\n",
      "3.0219899580001766 0.9525420069694519 9230\n",
      "[11, 10, 3, 12, 14, 5, 13, 7]\n",
      "3.0392005409999 0.9550406336784363 10203\n",
      "3.036500624999917 0.9637359976768494 10203\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1]\n",
      "3.243418041000041 0.9639858603477478 11176\n",
      "3.047962790999918 0.9671674966812134 11176\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8]\n",
      "3.0674689579996084 0.9679670929908752 12149\n",
      "3.0663602089998676 0.9687166810035706 12149\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8, 15]\n",
      "3.082118082999841 0.9698994159698486 13122\n",
      "3.0801345830000173 0.9729310870170593 13122\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8, 15, 2]\n",
      "3.0965657500000816 0.9748467206954956 14095\n",
      "3.0951707090002856 0.9785114526748657 14095\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8, 15, 2, 6]\n",
      "3.1132895410000856 0.9789612293243408 15068\n",
      "3.1110996249999516 0.9813432693481445 15068\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8, 15, 2, 6, 4]\n",
      "3.126736291999805 0.9819929599761963 16041\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8, 15, 2, 6, 4, 0]\n",
      "3.150094374999753 0.9820762276649475 17014\n",
      "[11, 10, 3, 12, 14, 5, 13, 7, 1, 8, 15, 2, 6, 4, 0, 9]\n"
     ]
    }
   ],
   "source": [
    "find_best_feature_in_select(layer_3_define, [11], list(range(16)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "model = torch.load('./compressed_base_model_weight.pt')['model']\n",
    "\n",
    "weights = model.feature_extractor.layer2.conv.weight\n",
    "bias = model.feature_extractor.layer2.conv.bias\n",
    "\n",
    "weights = weights.detach().cpu().numpy()\n",
    "bias = bias.detach().cpu().numpy()\n",
    "\n",
    "weights = copy.deepcopy(weights)\n",
    "bias = copy.deepcopy(bias)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.06821202, 0.17463163, 0.        ],\n       [0.18747228, 0.37420434, 0.        ],\n       [0.24220821, 0.34179688, 0.        ]], dtype=float32)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(weights[0, 3, :, 1:], ((0, 0), (0, 1)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.16466019,  0.06821202,  0.17463163],\n       [-0.37800136,  0.18747228,  0.37420434],\n       [-0.40203416,  0.24220821,  0.34179688]], dtype=float32)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0, 3, :, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.16466019,  0.06821202,  0.17463163],\n       [-0.37800136,  0.18747228,  0.37420434],\n       [-0.40203416,  0.24220821,  0.34179688]], dtype=float32)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0, 3, :, :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16466019  0.06821202  0.17463163]\n",
      " [-0.37800136  0.18747228  0.37420434]\n",
      " [-0.40203416  0.24220821  0.34179688]]\n"
     ]
    }
   ],
   "source": [
    "print(weights[0, 3, :, :])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 가중치 해석\n",
    "\n",
    "CNN을 거치고 나면 합성곱 필터는 학습데이터에 의해 세부 필터값이 정해진다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def find_weight_relations(weight):\n",
    "    left_to_right =  (np.pad(weight[:, 1:], ((0, 0), (0, 1))) - weight[:, :])[:, :2] # left -> right\n",
    "    top_to_bottom = ((np.pad(weight[1:, :], ((0, 1), (0, 0)))) - weight[:, :])[:2] # top -> bottom\n",
    "    # cross_delta = (np.pad(weight[1:, 1:], ((0, 1), (0, 1))) - weight[:, :])[[0, 1], [0, 1]] # cross weights delta\n",
    "    # w += [[(len(weights[0, 3]) + 1)*(i+1) - len(weights[0, 3]), (len(weights[0, 3]) + 1)*(i+2) - len(weights[0, 3]), abs(cross_delta[i])] for i in range(2)]\n",
    "\n",
    "    return [[i*3+1 +j, j+2+i*3,\n",
    "             left_to_right[i, j]]\n",
    "            for i in range(3) for j in range(2)] + \\\n",
    "           [[i*3+1+j, (i+1)*3+j+1, top_to_bottom[i, j]]\n",
    "            for i in range(2) for j in range(3)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "parent = dict()\n",
    "rank = dict()\n",
    "\n",
    "#vertice 초기화\n",
    "def make_set(vertice):\n",
    "    parent[vertice] = vertice\n",
    "    rank[vertice] = 0\n",
    "\n",
    "#해당 vertice의 최상위 정점을 찾는다\n",
    "def find(vertice):\n",
    "    if parent[vertice] != vertice:\n",
    "        parent[vertice] = find(parent[vertice])\n",
    "    return parent[vertice]\n",
    "\n",
    "#두 정점을 연결한다\n",
    "def union(vertice1, vertice2):\n",
    "    root1 = find(vertice1)\n",
    "    root2 = find(vertice2)\n",
    "    if root1 != root2:\n",
    "        if rank[root1] > rank[root2]:\n",
    "            parent[root2] = root1\n",
    "        else:\n",
    "            parent[root1] = root2\n",
    "            if rank[root1] == rank[root2]:\n",
    "                rank[root2] += 1\n",
    "\n",
    "def kruskal(graph):\n",
    "    minimum_spanning_tree = []\n",
    "\n",
    "    #초기화\n",
    "    for vertice in graph['vertices']:\n",
    "        make_set(vertice)\n",
    "\n",
    "    #간선 weight 기반 sorting\n",
    "    edges = graph['edges']\n",
    "    edges.sort()\n",
    "\n",
    "    #간선 연결 (사이클 없게)\n",
    "    for edge in edges:\n",
    "        weight, vertice1, vertice2 = edge\n",
    "        if find(vertice1) != find(vertice2):\n",
    "            union(vertice1, vertice2)\n",
    "            minimum_spanning_tree.append(edge)\n",
    "\n",
    "    return minimum_spanning_tree\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "1 - 2   3\n",
    "    |   |\n",
    "4 - 5 - 6\n",
    "|\n",
    "7 - 8 - 9\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== <weight[0, 0]> ===================\n",
      "1\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "            └── 9\n",
      "2\n",
      "├── 3\n",
      "└── 5\n",
      "    └── 6\n",
      "=================== <weight[0, 1]> ===================\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "└── 2\n",
      "    ├── 3\n",
      "    └── 5\n",
      "        ├── 6\n",
      "        └── 8\n",
      "            └── 9\n",
      "=================== <weight[0, 2]> ===================\n",
      "8\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "└── 2\n",
      "    └── 5\n",
      "        └── 6\n",
      "            └── 9\n",
      "3\n",
      "=================== <weight[0, 3]> ===================\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "└── 2\n",
      "    ├── 3\n",
      "    └── 5\n",
      "        └── 8\n",
      "            └── 9\n",
      "6\n",
      "=================== <weight[1, 0]> ===================\n",
      "8\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "└── 2\n",
      "    ├── 3\n",
      "    └── 5\n",
      "        └── 6\n",
      "            └── 9\n",
      "=================== <weight[1, 1]> ===================\n",
      "1\n",
      "├── 4\n",
      "└── 2\n",
      "    └── 3\n",
      "        └── 6\n",
      "            └── 9\n",
      "5\n",
      "7\n",
      "└── 8\n",
      "=================== <weight[1, 2]> ===================\n",
      "1\n",
      "└── 2\n",
      "    └── 3\n",
      "        └── 6\n",
      "4\n",
      "└── 7\n",
      "    └── 8\n",
      "        └── 9\n",
      "5\n",
      "=================== <weight[1, 3]> ===================\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "│       └── 8\n",
      "│           └── 9\n",
      "└── 2\n",
      "3\n",
      "└── 6\n",
      "5\n",
      "=================== <weight[2, 0]> ===================\n",
      "1\n",
      "├── 2\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "3\n",
      "└── 6\n",
      "    └── 9\n",
      "5\n",
      "=================== <weight[2, 1]> ===================\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "│       └── 8\n",
      "└── 2\n",
      "3\n",
      "└── 6\n",
      "    └── 9\n",
      "5\n",
      "=================== <weight[2, 2]> ===================\n",
      "1\n",
      "├── 4\n",
      "└── 2\n",
      "    ├── 5\n",
      "    │   └── 8\n",
      "    │       └── 9\n",
      "    └── 3\n",
      "        └── 6\n",
      "7\n",
      "=================== <weight[2, 3]> ===================\n",
      "1\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "2\n",
      "└── 5\n",
      "    └── 6\n",
      "        └── 9\n",
      "3\n",
      "=================== <weight[3, 0]> ===================\n",
      "1\n",
      "└── 4\n",
      "    ├── 5\n",
      "    └── 7\n",
      "        └── 8\n",
      "            └── 9\n",
      "2\n",
      "└── 3\n",
      "    └── 6\n",
      "=================== <weight[3, 1]> ===================\n",
      "1\n",
      "├── 4\n",
      "└── 2\n",
      "    ├── 3\n",
      "    └── 5\n",
      "        └── 6\n",
      "            └── 9\n",
      "7\n",
      "└── 8\n",
      "=================== <weight[3, 2]> ===================\n",
      "1\n",
      "├── 4\n",
      "└── 2\n",
      "    ├── 3\n",
      "    └── 5\n",
      "        └── 8\n",
      "            └── 9\n",
      "6\n",
      "7\n",
      "=================== <weight[3, 3]> ===================\n",
      "1\n",
      "└── 4\n",
      "    └── 5\n",
      "        └── 8\n",
      "            └── 9\n",
      "2\n",
      "└── 3\n",
      "6\n",
      "7\n",
      "=================== <weight[4, 0]> ===================\n",
      "1\n",
      "├── 2\n",
      "└── 4\n",
      "    ├── 7\n",
      "    └── 5\n",
      "        └── 8\n",
      "            └── 9\n",
      "3\n",
      "└── 6\n",
      "=================== <weight[4, 1]> ===================\n",
      "1\n",
      "└── 2\n",
      "    └── 3\n",
      "        └── 6\n",
      "4\n",
      "└── 7\n",
      "    └── 8\n",
      "        └── 9\n",
      "5\n",
      "=================== <weight[4, 2]> ===================\n",
      "1\n",
      "├── 2\n",
      "│   └── 3\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "5\n",
      "└── 6\n",
      "    └── 9\n",
      "=================== <weight[4, 3]> ===================\n",
      "1\n",
      "├── 2\n",
      "│   └── 3\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "            └── 9\n",
      "5\n",
      "└── 6\n",
      "=================== <weight[5, 0]> ===================\n",
      "1\n",
      "├── 2\n",
      "│   └── 3\n",
      "│       └── 6\n",
      "│           └── 9\n",
      "└── 4\n",
      "    └── 5\n",
      "7\n",
      "└── 8\n",
      "=================== <weight[5, 1]> ===================\n",
      "1\n",
      "├── 4\n",
      "└── 2\n",
      "    └── 3\n",
      "        └── 6\n",
      "            └── 9\n",
      "5\n",
      "7\n",
      "└── 8\n",
      "=================== <weight[5, 2]> ===================\n",
      "1\n",
      "└── 4\n",
      "    ├── 5\n",
      "    └── 7\n",
      "        └── 8\n",
      "            └── 9\n",
      "2\n",
      "3\n",
      "└── 6\n",
      "=================== <weight[5, 3]> ===================\n",
      "8\n",
      "1\n",
      "├── 4\n",
      "│   └── 7\n",
      "└── 2\n",
      "    └── 5\n",
      "        └── 6\n",
      "            └── 9\n",
      "3\n",
      "=================== <weight[6, 0]> ===================\n",
      "1\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "2\n",
      "├── 5\n",
      "└── 3\n",
      "    └── 6\n",
      "        └── 9\n",
      "=================== <weight[6, 1]> ===================\n",
      "1\n",
      "└── 2\n",
      "    └── 3\n",
      "        └── 6\n",
      "4\n",
      "└── 7\n",
      "    └── 8\n",
      "        └── 9\n",
      "5\n",
      "=================== <weight[6, 2]> ===================\n",
      "1\n",
      "└── 2\n",
      "    ├── 3\n",
      "    └── 5\n",
      "        ├── 8\n",
      "        └── 6\n",
      "            └── 9\n",
      "4\n",
      "7\n",
      "=================== <weight[6, 3]> ===================\n",
      "1\n",
      "└── 4\n",
      "    └── 7\n",
      "        └── 8\n",
      "2\n",
      "└── 3\n",
      "    └── 6\n",
      "        └── 9\n",
      "5\n",
      "=================== <weight[7, 0]> ===================\n",
      "1\n",
      "└── 2\n",
      "    └── 3\n",
      "        └── 6\n",
      "            └── 9\n",
      "4\n",
      "└── 7\n",
      "    └── 8\n",
      "5\n",
      "=================== <weight[7, 1]> ===================\n",
      "1\n",
      "└── 2\n",
      "    └── 5\n",
      "        └── 6\n",
      "3\n",
      "4\n",
      "└── 7\n",
      "    └── 8\n",
      "        └── 9\n",
      "=================== <weight[7, 2]> ===================\n",
      "1\n",
      "└── 4\n",
      "    ├── 7\n",
      "    └── 5\n",
      "        └── 8\n",
      "            └── 9\n",
      "2\n",
      "3\n",
      "└── 6\n",
      "=================== <weight[7, 3]> ===================\n",
      "1\n",
      "└── 2\n",
      "    └── 5\n",
      "        ├── 6\n",
      "        └── 8\n",
      "            └── 9\n",
      "3\n",
      "4\n",
      "└── 7\n"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree\n",
    "\n",
    "find_result = \"\"\n",
    "\n",
    "for in_ in range(8):\n",
    "    for out_ in range(4):\n",
    "        print(f'=================== <weight[{in_}, {out_}]> ===================')\n",
    "        find_result += f'=================== <weight[{in_}, {out_}]> ===================\\n'\n",
    "        feed_weight = weights[in_, out_]\n",
    "\n",
    "        w = find_weight_relations(feed_weight)\n",
    "        connections = sorted(w, reverse=False, key=lambda x: x[-1])\n",
    "        connections = list(map(lambda x: [x[2], str(x[0]), str(x[1])], connections))\n",
    "\n",
    "        graph = {\n",
    "            'vertices': list(map(str, range(1, 10))),\n",
    "            'edges': connections\n",
    "        }\n",
    "\n",
    "        res = kruskal(graph)\n",
    "\n",
    "        nodes = [\n",
    "             Node(i, weight=feed_weight[(i-1) // 3, (i-1) % 3]) for i in range(1, 10)\n",
    "        ]\n",
    "\n",
    "        for r in res:\n",
    "            start, end = map(int, r[1:])\n",
    "            nodes[end-1].parent = nodes[start-1]\n",
    "\n",
    "        # mst가 space에 몇개 있는지\n",
    "        roots = {x.root.name for x in nodes}\n",
    "\n",
    "        for root in roots:\n",
    "            for pre, fill, node in RenderTree(nodes[root-1]):\n",
    "                find_result += f'{pre}{node.name}\\n'\n",
    "                print(\"%s%s\" % (pre, node.name))\n",
    "\n",
    "with open('layer_2_weight_trees_kruskal', \"w\") as f:\n",
    "    f.write(find_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.16466019,  0.06821202,  0.17463163],\n       [-0.37800136,  0.18747228,  0.37420434],\n       [-0.40203416,  0.24220821,  0.34179688]], dtype=float32)"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1 - 2 - 3\n",
    "|   |\n",
    "4   5   6\n",
    "|   |   |\n",
    "7   8 - 9\n",
    "'''\n",
    "\n",
    "'''\n",
    "1 - 2 - 3\n",
    "|   |   |\n",
    "4 - 5 - 6\n",
    "|   |   |\n",
    "7 - 8 - 9\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 루트노드를 기준으로 가지가 길게 이어진 것을 살려보자"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.16466019,  0.06821202,  0.17463163],\n       [-0.37800136,  0.18747228,  0.37420434],\n       [-0.40203416,  0.24220821,  0.34179688]], dtype=float32)"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0, 3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 파라미터 수는 변하지 않는거 같은데..?\n",
    "# 최적의 가중치를 찾는다는게\n",
    "# base model의 정확도가 0.984인 결과를 도출했다.\n",
    "# 그 자체가 최적의 가중치임\n",
    "# 모델 경량화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "img, target = next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2)"
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img[0].squeeze(), cmap='gray')\n",
    "target[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 1, 28, 28])"
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 3, 3])"
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = torch.tensor([[[\n",
    "    [-0.16466, -0.068212, 0],\n",
    "    [0, 0.187472, 0.374204],\n",
    "    [0, 0, 0.341797]\n",
    "]]])\n",
    "\n",
    "ss.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x289a78550>"
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcCElEQVR4nO3db2yV9f3/8dexwAHhcLSB9pxK7RoH2aSVbcqADrWgNDaTTOsMarJAshmdQEKqMWPcsNkNalwkLGGyaL5hkIFyY/7bIEK30iJhzIo4OzCujiI19qyjak8teGrL53eDcH47/PVzOKfvnvb5SK7Ec53rxfXm4rIvLs451wk455wAADBwlfUAAIDRixICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAmTHWA5zr9OnT+uSTTxQKhRQIBKzHAQB4cs6pt7dXRUVFuuqqS1/rDLsS+uSTT1RcXGw9BgDgCnV0dGjatGmX3GbYlVAoFJIk3XjjjcrLyzOeBgDga3BwUEeOHEn+PL+UrJXQc889p1//+tfq7OzUzJkztX79et16662XzZ39J7i8vDxKCABy2Nd5SSUrb0zYvn27Vq1apTVr1ujQoUO69dZbVV1drePHj2djdwCAHJWVElq3bp1++tOf6mc/+5m+/e1va/369SouLtbGjRuzsTsAQI7KeAn19/fr4MGDqqqqSllfVVWl/fv3n7d9IpFQPB5PWQAAo0PGS+jEiRMaHBxUYWFhyvrCwkLFYrHztq+vr1c4HE4uvDMOAEaPrH1Y9dwXpJxzF3yRavXq1erp6UkuHR0d2RoJADDMZPzdcVOmTFFeXt55Vz1dXV3nXR1JUjAYVDAYzPQYAIAckPEroXHjxunmm29WQ0NDyvqGhgZVVFRkencAgByWlc8J1dbW6ic/+YluueUWzZs3T88//7yOHz+uRx99NBu7AwDkqKyU0JIlS9Td3a1f/epX6uzsVFlZmXbu3KmSkpJs7A4AkKMCzjlnPcT/isfjCofDKi8v544JAJCDBgcH1draqp6eHk2ePPmS2/JVDgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMDMGOsBAHw9kyZN8s5MnTo1rX3NmDHDOzNhwgTvzKlTp7wzTU1N3plEIuGdwdDgSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZbmAKGLjhhhu8M7Nnz/bOlJaWemfS3VdJSYl3ZmBgwDuzatUq70xLS4t3RkpvPvjhSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZbmAK/I+8vDzvzHe+8x3vzMKFC70z8+fP986k6z//+Y935vPPP/fOXHWV/9+Djxw54p1pb2/3zkhSNBr1zowZw49VH1wJAQDMUEIAADMZL6G6ujoFAoGUJRKJZHo3AIARICv/eDlz5kz95S9/ST5O59/ZAQAjX1ZKaMyYMVz9AAAuKyuvCbW1tamoqEilpaV64IEHdPTo0Ytum0gkFI/HUxYAwOiQ8RKaM2eOtmzZol27dumFF15QLBZTRUWFuru7L7h9fX29wuFwcikuLs70SACAYSrjJVRdXa377rtP5eXluvPOO7Vjxw5J0ubNmy+4/erVq9XT05NcOjo6Mj0SAGCYyvqnqiZOnKjy8nK1tbVd8PlgMKhgMJjtMQAAw1DWPyeUSCT0/vvvp/XJYwDAyJbxEnriiSfU3Nys9vZ2/f3vf9ePf/xjxeNxLV26NNO7AgDkuIz/c9zHH3+sBx98UCdOnNDUqVM1d+5cHThwQCUlJZneFQAgx2W8hF566aVM/5LAkLn22mu9M/fff793ZubMmd6Zf/3rX96ZP//5z94ZSXrnnXe8M3fffbd35qabbvLOfPXVV0OSkSTnXFo5fH3cOw4AYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAICZrH+pHZBL0vmCxdOnT3tn3njjDe/M9u3bvTNvvvmmd0aS8vPzvTNFRUXemZMnT3pn+vv7vTPp/BlhaHAlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAww120gf/R3d3tndm2bZt35siRI96Zd955xzsTCoW8M5J0//33e2d+8IMfeGdeeeUV70xnZ6d3Jl2BQGDI9jVacSUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADDcwBf7Hl19+6Z1pbW31zvT19XlniouLvTM33nijd0aSFi5c6J1J52af+/fv98709PR4Z6699lrvjCSNGcOPyGzjSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZ7s4HXKF0btw5adKkIcnccccd3hlJ+u53v+udOXr0qHemra3NOzMwMOCdmThxoncGQ4MrIQCAGUoIAGDGu4T27t2rxYsXq6ioSIFAQK+++mrK88451dXVqaioSBMmTFBlZaUOHz6cqXkBACOIdwn19fVp1qxZ2rBhwwWff+aZZ7Ru3Tpt2LBBLS0tikQiWrRokXp7e694WADAyOL9xoTq6mpVV1df8DnnnNavX681a9aopqZGkrR582YVFhZq27ZteuSRR65sWgDAiJLR14Ta29sVi8VUVVWVXBcMBnX77bdf9Gt8E4mE4vF4ygIAGB0yWkKxWEySVFhYmLK+sLAw+dy56uvrFQ6Hk0txcXEmRwIADGNZeXfcuZ+bcM5d9LMUq1evVk9PT3Lp6OjIxkgAgGEoox9WjUQiks5cEUWj0eT6rq6u866OzgoGgwoGg5kcAwCQIzJ6JVRaWqpIJKKGhobkuv7+fjU3N6uioiKTuwIAjADeV0JffPGFPvzww+Tj9vZ2vfvuu8rPz9f111+vVatWae3atZo+fbqmT5+utWvX6uqrr9ZDDz2U0cEBALnPu4TefvttLViwIPm4trZWkrR06VL9/ve/15NPPqlTp07pscce02effaY5c+Zo9+7dCoVCmZsaADAieJdQZWWlnHMXfT4QCKiurk51dXVXMheAc8yYMcM7M2/evLT2dan/xy/mxRdf9M60t7d7Z9J5DXn8+PHeGQwN7h0HADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADCT0W9WBfD15OXleWfuvPNO78z06dO9M5K0f/9+70xjY6N35uTJk96Z6667zjuD4YsrIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGa4gSlgYMGCBd6Z8vJy78zHH3/snZGkP/7xj96ZEydOeGfC4bB35pprrvHOYPjiSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZbmA6wkydOtU7M23atLT2lc6NJEOhUFr7Gir9/f3emd7eXu9MTU2Nd+amm27yzjz//PPeGUnas2ePd6avr887U1xc7J3ByMKVEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADPcwHQYS+dmpHfffbd3ZtasWd4ZSSotLfXOFBYWemeCwaB3Jl2JRMI78+mnn3pn0rn5aywW88689tpr3hlJisfj3pl0/mwnT57sncHIwpUQAMAMJQQAMONdQnv37tXixYtVVFSkQCCgV199NeX5ZcuWKRAIpCxz587N1LwAgBHEu4T6+vo0a9Ysbdiw4aLb3HXXXers7EwuO3fuvKIhAQAjk/cbE6qrq1VdXX3JbYLBoCKRSNpDAQBGh6y8JtTU1KSCggLNmDFDDz/8sLq6ui66bSKRUDweT1kAAKNDxkuourpaW7duVWNjo5599lm1tLRo4cKFF33ra319vcLhcHLhO+cBYPTI+OeElixZkvzvsrIy3XLLLSopKdGOHTtUU1Nz3varV69WbW1t8nE8HqeIAGCUyPqHVaPRqEpKStTW1nbB54PB4JB+GBEAMHxk/XNC3d3d6ujoUDQazfauAAA5xvtK6IsvvtCHH36YfNze3q53331X+fn5ys/PV11dne677z5Fo1EdO3ZMv/zlLzVlyhTde++9GR0cAJD7vEvo7bff1oIFC5KPz76es3TpUm3cuFGtra3asmWLPv/8c0WjUS1YsEDbt29XKBTK3NQAgBHBu4QqKyvlnLvo87t27bqigfD/lZWVeWd++MMfemeuu+4674wk7du3zzvT3NzsnUnnRq4FBQXemXQFAgHvTHd3t3fms88+887k5eV5ZyTp9OnT3plJkyaltS+Mbtw7DgBghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABgJuvfrIr0pXN368mTJ3tnYrGYd0aSfvOb33hnTpw44Z1ZvHixd2bOnDneGUmaOHGid+bYsWPemW9+85vemauvvto7M3/+fO+MJHV0dHhnxo8fn9a+MLpxJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMNzAdxv797397Z3p6erwzAwMD3hlJuvHGG70zg4OD3plFixZ5Z6ZNm+adkaTXXnvNO7N7927vTDo3WL3jjju8M9/4xje8M5J06tQp70x/f7935pprrvHOYGThSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZbmA6jP3jH//wzuzdu9c7U1FR4Z2RpHvvvdc7k84NK8eOHeud+etf/+qdkaStW7d6Z9566y3vTFtbm3dm1qxZ3pl0b+QaDoe9M59++mla+8LoxpUQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM9zAdBg7efKkd6axsdE789VXX3lnJGnq1KnemX379nln/vnPf3pnDhw44J2RpA8//NA7k84NVtPR39/vnUn3Bqbz5s3zzvz3v//1zhw7dsw7g5GFKyEAgBlKCABgxquE6uvrNXv2bIVCIRUUFOiee+7RBx98kLKNc051dXUqKirShAkTVFlZqcOHD2d0aADAyOBVQs3NzVq+fLkOHDighoYGDQwMqKqqSn19fcltnnnmGa1bt04bNmxQS0uLIpGIFi1apN7e3owPDwDIbV5vTHjjjTdSHm/atEkFBQU6ePCgbrvtNjnntH79eq1Zs0Y1NTWSpM2bN6uwsFDbtm3TI488krnJAQA574peE+rp6ZEk5efnS5La29sVi8VUVVWV3CYYDOr222/X/v37L/hrJBIJxePxlAUAMDqkXULOOdXW1mr+/PkqKyuTJMViMUlSYWFhyraFhYXJ585VX1+vcDicXIqLi9MdCQCQY9IuoRUrVui9997Tiy++eN5zgUAg5bFz7rx1Z61evVo9PT3JpaOjI92RAAA5Jq0Pq65cuVKvv/669u7dm/JhuEgkIunMFVE0Gk2u7+rqOu/q6KxgMKhgMJjOGACAHOd1JeSc04oVK/Tyyy+rsbFRpaWlKc+XlpYqEomooaEhua6/v1/Nzc2qqKjIzMQAgBHD60po+fLl2rZtm1577TWFQqHk6zzhcFgTJkxQIBDQqlWrtHbtWk2fPl3Tp0/X2rVrdfXVV+uhhx7Kym8AAJC7vEpo48aNkqTKysqU9Zs2bdKyZcskSU8++aROnTqlxx57TJ999pnmzJmj3bt3KxQKZWRgAMDI4VVCzrnLbhMIBFRXV6e6urp0Z8IVOPcOFl9HujeRnDRpknemra3NO/PRRx95Z06fPu2dkdK7KevZjyj4GDPG/+XYgYEB70w6vx9Jyc/5+Xjrrbe8M1/nZ8q50jkfMHxx7zgAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgJm0vlkVw1c6d1pOJyNJPT093pl07m5dUFDgnbn22mu9M5I0bty4tHJDIRAIeGfy8vKyMMmF7d692zvz/vvve2fSOQ7FxcXeGQwNroQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCY4QamSNuYMf6nzzXXXJP5QUaJN9980zvz6aefprWvQ4cOeWfa29u9M6dOnfLOlJSUeGcwfHElBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAw3MAVyxJ49e7wzf/rTn9La17Fjx7wzAwMD3pmCggLvzPjx470zGL64EgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGG5gCI9ikSZPSypWVlWV4EuDCuBICAJihhAAAZrxKqL6+XrNnz1YoFFJBQYHuueceffDBBynbLFu2TIFAIGWZO3duRocGAIwMXiXU3Nys5cuX68CBA2poaNDAwICqqqrU19eXst1dd92lzs7O5LJz586MDg0AGBm83pjwxhtvpDzetGmTCgoKdPDgQd12223J9cFgUJFIJDMTAgBGrCt6Tainp0eSlJ+fn7K+qalJBQUFmjFjhh5++GF1dXVd9NdIJBKKx+MpCwBgdEi7hJxzqq2t1fz581PezlldXa2tW7eqsbFRzz77rFpaWrRw4UIlEokL/jr19fUKh8PJpbi4ON2RAAA5JuCcc+kEly9frh07dmjfvn2aNm3aRbfr7OxUSUmJXnrpJdXU1Jz3fCKRSCmoeDyu4uJilZeXKy8vL53RAACGBgcH1draqp6eHk2ePPmS26b1YdWVK1fq9ddf1969ey9ZQJIUjUZVUlKitra2Cz4fDAYVDAbTGQMAkOO8Ssg5p5UrV+qVV15RU1OTSktLL5vp7u5WR0eHotFo2kMCAEYmr9eEli9frj/84Q/atm2bQqGQYrGYYrGYTp06JUn64osv9MQTT+hvf/ubjh07pqamJi1evFhTpkzRvffem5XfAAAgd3ldCW3cuFGSVFlZmbJ+06ZNWrZsmfLy8tTa2qotW7bo888/VzQa1YIFC7R9+3aFQqGMDQ0AGBm8/znuUiZMmKBdu3Zd0UAAgNGDe8cBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMyMsR7gXM45SdLg4KDxJACAdJz9+X325/mlDLsS6u3tlSQdOXLEeBIAwJXo7e1VOBy+5DYB93WqagidPn1an3zyiUKhkAKBQMpz8XhcxcXF6ujo0OTJk40mtMdxOIPjcAbH4QyOwxnD4Tg459Tb26uioiJdddWlX/UZdldCV111laZNm3bJbSZPnjyqT7KzOA5ncBzO4DicwXE4w/o4XO4K6CzemAAAMEMJAQDM5FQJBYNBPfXUUwoGg9ajmOI4nMFxOIPjcAbH4YxcOw7D7o0JAIDRI6euhAAAIwslBAAwQwkBAMxQQgAAMzlVQs8995xKS0s1fvx43XzzzXrzzTetRxpSdXV1CgQCKUskErEeK+v27t2rxYsXq6ioSIFAQK+++mrK88451dXVqaioSBMmTFBlZaUOHz5sM2wWXe44LFu27LzzY+7cuTbDZkl9fb1mz56tUCikgoIC3XPPPfrggw9SthkN58PXOQ65cj7kTAlt375dq1at0po1a3To0CHdeuutqq6u1vHjx61HG1IzZ85UZ2dncmltbbUeKev6+vo0a9Ysbdiw4YLPP/PMM1q3bp02bNiglpYWRSIRLVq0KHkfwpHicsdBku66666U82Pnzp1DOGH2NTc3a/ny5Tpw4IAaGho0MDCgqqoq9fX1JbcZDefD1zkOUo6cDy5HfP/733ePPvpoyrpvfetb7he/+IXRREPvqaeecrNmzbIew5Qk98orryQfnz592kUiEff0008n13355ZcuHA673/3udwYTDo1zj4Nzzi1dutT96Ec/MpnHSldXl5PkmpubnXOj93w49zg4lzvnQ05cCfX39+vgwYOqqqpKWV9VVaX9+/cbTWWjra1NRUVFKi0t1QMPPKCjR49aj2Sqvb1dsVgs5dwIBoO6/fbbR925IUlNTU0qKCjQjBkz9PDDD6urq8t6pKzq6emRJOXn50savefDucfhrFw4H3KihE6cOKHBwUEVFhamrC8sLFQsFjOaaujNmTNHW7Zs0a5du/TCCy8oFoupoqJC3d3d1qOZOfvnP9rPDUmqrq7W1q1b1djYqGeffVYtLS1auHChEomE9WhZ4ZxTbW2t5s+fr7KyMkmj83y40HGQcud8GHZ30b6Uc7/awTl33rqRrLq6Ovnf5eXlmjdvnm644QZt3rxZtbW1hpPZG+3nhiQtWbIk+d9lZWW65ZZbVFJSoh07dqimpsZwsuxYsWKF3nvvPe3bt++850bT+XCx45Ar50NOXAlNmTJFeXl55/1Npqur67y/8YwmEydOVHl5udra2qxHMXP23YGcG+eLRqMqKSkZkefHypUr9frrr2vPnj0pX/0y2s6Hix2HCxmu50NOlNC4ceN08803q6GhIWV9Q0ODKioqjKayl0gk9P777ysajVqPYqa0tFSRSCTl3Ojv71dzc/OoPjckqbu7Wx0dHSPq/HDOacWKFXr55ZfV2Nio0tLSlOdHy/lwueNwIcP2fDB8U4SXl156yY0dO9b93//9nzty5IhbtWqVmzhxojt27Jj1aEPm8ccfd01NTe7o0aPuwIED7u6773ahUGjEH4Pe3l536NAhd+jQISfJrVu3zh06dMh99NFHzjnnnn76aRcOh93LL7/sWltb3YMPPuii0aiLx+PGk2fWpY5Db2+ve/zxx93+/ftde3u727Nnj5s3b5677rrrRtRx+PnPf+7C4bBrampynZ2dyeXkyZPJbUbD+XC545BL50POlJBzzv32t791JSUlbty4ce573/teytsRR4MlS5a4aDTqxo4d64qKilxNTY07fPiw9VhZt2fPHifpvGXp0qXOuTNvy33qqadcJBJxwWDQ3Xbbba61tdV26Cy41HE4efKkq6qqclOnTnVjx451119/vVu6dKk7fvy49dgZdaHfvyS3adOm5Daj4Xy43HHIpfOBr3IAAJjJideEAAAjEyUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADP/D2mwTBOEvxo2AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = F.conv2d(input=img[0],\n",
    "               # weight=torch.tensor(weights[0, 3][np.newaxis][np.newaxis]),\n",
    "               weight=ss,\n",
    "               bias=torch.tensor(bias[0][np.newaxis]),\n",
    "               stride=1,\n",
    "               padding='same')\n",
    "plt.imshow(res.squeeze(), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x28cf490a0>"
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = F.conv2d(input=img[0],\n",
    "               weight=torch.tensor(weights[0, 3][np.newaxis][np.newaxis]),\n",
    "               # weight=ss,\n",
    "               bias=torch.tensor(bias[0][np.newaxis]),\n",
    "               stride=1,\n",
    "               padding='same')\n",
    "plt.imshow(res.squeeze(), cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
